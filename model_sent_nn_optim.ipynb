{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os.path as p\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "import print_n_log\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from definitions import *\n",
    "from model_helper_functions import *\n",
    "from dataset_helper_functions import *\n",
    "from sent_nn import SentNN\n",
    "from feature_nn import FeatureNN\n",
    "from pair_nn import PairNN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from debates_dataset import DebatesDataset\n",
    "from early_stopping import EarlyStopping\n",
    "from optuna.trial import TrialState\n",
    "from torchvision import transforms\n",
    "# my transforms\n",
    "from transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "optim_path = os.path.join(EXP_DIR_PATH, 'sent-nn', 'optimization')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_uw_ratio = 0\n",
    "dataset_frac = 0.2\n",
    "worthy_frac = 0.03\n",
    "slf_dim = 0\n",
    "rs = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dev_path = p.join(PROC_DATA_DIR_PATH, 'dev')\n",
    "\n",
    "    data_paths = {\n",
    "        'dev': [\n",
    "            p.join(dev_path, 'dev.tsv'),\n",
    "        ],\n",
    "        'test': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'test', 'test_combined.tsv'),\n",
    "        ],\n",
    "        'train': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'train', 'train_combined.tsv'),\n",
    "        ],\n",
    "        'val': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'val', 'val_combined.tsv'),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    for dtype, dpaths in data_paths.items():\n",
    "        try:\n",
    "            data[dtype] = pd.read_csv(dpaths[0], sep='\\t', index_col=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e.args)\n",
    "            exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets and DataLoaders, takes trial as input to be able to suggest values for variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(trial, batch_size, stopwords_type):\n",
    "    global train_uw_ratio, slf_dim\n",
    "    # dev_df, test_df, train_df, val_df = data.values()\n",
    "    subsets = {}\n",
    "    for k, df in data.items():\n",
    "\n",
    "        n_subset = int(len(df)*dataset_frac)\n",
    "\n",
    "        worthy_df = df.loc[df['label'] == 1]\n",
    "        n_worthy = int(min(n_subset*worthy_frac, len(worthy_df)))\n",
    "        worthy_df = worthy_df.sample(n=n_worthy, random_state=rs)\n",
    "\n",
    "        unworthy_df = df.loc[df['label'] == 0].sample(\n",
    "            n=n_subset-n_worthy,\n",
    "            random_state=rs\n",
    "        )\n",
    "        if k == 'train':\n",
    "            train_uw_ratio = len(unworthy_df) / len(worthy_df)\n",
    "        # sample(frac=1.0) -> shuffle\n",
    "        subsets[k] = worthy_df.append(unworthy_df).sample(frac=1.0, random_state=rs, ignore_index=True)\n",
    "\n",
    "    # TODO: for sentence level feature optimization    \n",
    "#     transforms_map = {\n",
    "#         'sum': Sum,\n",
    "#         'onehot': OneHot,\n",
    "#         'none': NoTransform\n",
    "#     }\n",
    "# #     transforms_options = list(transforms_map.keys())\n",
    "#     cw_map = {\n",
    "#         'count_words': CountWords,\n",
    "#         'none': NoTransform\n",
    "#     }\n",
    "#     cw_options = list(cw_map.keys())\n",
    "\n",
    "#     from_sel = trial.suggest_categorical('from_selection', [True, False])\n",
    "\n",
    "    # trial.suggest_categorical returns one of the keys of transforms_map, which then return Transform or None\n",
    "    # if transform --> initialize\n",
    "#     pos_feat = transforms_map[trial.suggest_categorical('pos_feature_type', transforms_options)]\n",
    "#     pos_feat = pos_feat(\n",
    "#         'pos', from_selection=from_sel, stopwords=stopwords_type\n",
    "#     )\n",
    "#     pos_feat = Sum('pos')\n",
    "\n",
    "#     tag_feat = transforms_map[trial.suggest_categorical('tag_feature_type', transforms_options)]\n",
    "#     tag_feat = tag_feat(\n",
    "#         'tag', from_selection=from_sel, stopwords=stopwords_type\n",
    "#     )\n",
    "    # feat combination optim\n",
    "#     tag_feat = trial.suggest_categorical('tag_feature', [True, False])\n",
    "#     tag_feat = Sum('tag', from_selection=feature_params['from_selection'], stopwords=stopwords_type) if tag_feat else NoTransform()\n",
    "    # param optim after feat combination optim\n",
    "#     tag_feat = transforms_map[feature_params['tag_feature_type']]\n",
    "#     tag_feat = tag_feat(\n",
    "#         'tag',\n",
    "#         from_selection=feature_params['from_selection'],\n",
    "#         stopwords=stopwords_type\n",
    "#     )\n",
    "#     dep_feat = transforms_map[trial.suggest_categorical('dep_feature_type', transforms_options)]\n",
    "#     dep_feat = dep_feat(\n",
    "#         'dep', from_selection=from_sel, stopwords=stopwords_type\n",
    "#     )\n",
    "    # feat combination optim\n",
    "#     dep_feat = trial.suggest_categorical('dep_feature', [True, False])\n",
    "#     dep_feat = Sum('dep', from_selection=feature_params['from_selection'], stopwords=stopwords_type) if dep_feat else NoTransform()\n",
    "\n",
    "#     dep_feat = Sum('dep')\n",
    "    # param optim after feat combination optim\n",
    "#     dep_feat = transforms_map[feature_params['dep_feature']]\n",
    "#     dep_feat = dep_feat(\n",
    "#         'dep',\n",
    "#         from_selection=feature_params['from_selection'],\n",
    "#         stopwords=stopwords_type\n",
    "#     )\n",
    "\n",
    "#     cw_feat = cw_map[trial.suggest_categorical('word_count_feature_type', cw_options)]\n",
    "#     cw_feat = cw_feat()\n",
    "    # feat combination optim\n",
    "#     cw_feat = cw_map[feature_params['word_count_feature_type']]()\n",
    "\n",
    "    \n",
    "#     transform_pipeline = transforms.Compose([\n",
    "#         HandleStopwords(stopwords=stopwords_type),\n",
    "# #         pos_feat,\n",
    "#         tag_feat,\n",
    "# #         dep_feat,\n",
    "#         cw_feat,\n",
    "#         ToBinary(6),\n",
    "#         ToTensor()\n",
    "#     ])\n",
    "    transform_pipeline = None\n",
    "#     transform_pipeline = None\n",
    "\n",
    "    train_dd = DebatesDataset(data=subsets['train'], transform=transform_pipeline)\n",
    "    val_dd = DebatesDataset(data=subsets['val'], transform=transform_pipeline)\n",
    "    test_dd = DebatesDataset(data=subsets['test'], transform=transform_pipeline)\n",
    "    \n",
    "    if transform_pipeline is not None:\n",
    "        slf_dim = train_dd[0][-1].size()[0] if torch.is_tensor(train_dd[0][-1]) else 0\n",
    "#     batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "#     batch_size = 16\n",
    "    train_loader = DataLoader(train_dd, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dd, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dd, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model setup + training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global logf_path\n",
    "    # this is here so that it can be accessed here and in get_loaders()\n",
    "#     stopwords_type = trial.suggest_categorical('stopwords_type', ['wstop', 'wostop'])\n",
    "#     stopwords_type = feature_params['stopwords_type']\n",
    "    stopwords_type = None\n",
    "#     stopwords_type = 'wstop'\n",
    "    # unused is test_loader\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "#     batch_size = params['batch_size']\n",
    "    train_loader, val_loader, _ = get_loaders(trial, batch_size, stopwords_type)\n",
    "    \n",
    "    # hyperparams opt\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5, step=0.01)\n",
    "#     hidden_dim = trial.suggest_categorical('hidden_dim', [128, 256, 512])\n",
    "#     w_seq = trial.suggest_categorical('with_sequential_layer', [True, False])\n",
    "#     n_hidden_layers = trial.suggest_int('n_hidden_layers', 1, 6)\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    opt_weight_decay = trial.suggest_float('optimizer_weigth_decay', 1e-6, 0.1, log=True)\n",
    "    pos_weight = trial.suggest_categorical('pos_weight', [1.0, train_uw_ratio])\n",
    "    emb_model_name = trial.suggest_categorical(\n",
    "        'embedding_model_name',\n",
    "        ['all-mpnet-base-v2', 'all-MiniLM-L6-v2', 'multi-qa-mpnet-base-dot-v1']\n",
    "    )\n",
    "#     fnn_hidden_dim = trial.suggest_categorical('fnn_hidden_dim', [128, 256, 512])\n",
    "#     fnn_n_layers = trial.suggest_int('fnn_n_hidden_layers', 1, 6)\n",
    "#     fnn_dropout = trial.suggest_float('fnn_dropout', 0.0, 0.5, step=0.01)\n",
    "    \n",
    "#     pnn_hidden_dim = trial.suggest_categorical('pnn_hidden_dim', [8, 16, 32, 64])\n",
    "#     pnn_dropout = trial.suggest_float('pnn_dropout', 0.0, 0.5, step=0.01)\n",
    "    \n",
    "    # temp_best\n",
    "#     dropout = params['dropout']\n",
    "#     hidden_dim = params['hidden_dim']\n",
    "#     w_seq = params['with_sequential_layer']\n",
    "#     lr = params['learning_rate']\n",
    "#     opt_weight_decay = params['optimizer_weigth_decay']\n",
    "#     pos_weight = train_uw_ratio if params['pos_weight'] > 1.0 else 1.0\n",
    "#     emb_model_name = params['embedding_model_name']\n",
    "\n",
    "\n",
    "#     fnn_hidden_dim = params['fnn_hidden_dim']\n",
    "#     fnn_n_layers = params['fnn_n_hidden_layers']\n",
    "#     fnn_dropout = params['fnn_dropout']\n",
    "    \n",
    "#     pnn_hidden_dim = params['pnn_hidden_dim']\n",
    "#     pnn_dropout = params['pnn_dropout']\n",
    "\n",
    "    \n",
    "    emb_size_map = {\n",
    "        'all-mpnet-base-v2': 768,\n",
    "        'all-MiniLM-L6-v2': 384,\n",
    "        'multi-qa-mpnet-base-dot-v1': 768\n",
    "    }\n",
    "    # emb_model_name = 'all-MiniLM-L6-v2'\n",
    "    embedding_model = SentenceTransformer(emb_model_name, device=device, cache_folder=SBERT_MODEL_PATH)\n",
    "    \n",
    "    model = SentNN(\n",
    "        embeddings_dim=emb_size_map[emb_model_name],\n",
    "        sentence_level_feature_dim=slf_dim,\n",
    "        dropout=dropout,\n",
    "#         hidden_dim=hidden_dim,\n",
    "#         n_hidden_layers=n_hidden_layers\n",
    "    ).to(device)\n",
    "                         \n",
    "#     feature_model = FeatureNN(\n",
    "#         feature_dim=slf_dim,\n",
    "#         hidden_dim=fnn_hidden_dim,\n",
    "#         n_hidden_layers=fnn_n_layers,\n",
    "#         dropout=fnn_dropout\n",
    "#     ).to(device)\n",
    "    \n",
    "#     pair_model = PairNN(\n",
    "#         model, feature_model,\n",
    "#         hidden_dim=pnn_hidden_dim,\n",
    "#         dropout=pnn_dropout\n",
    "#     ).to(device)\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=opt_weight_decay)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]).to(device))\n",
    "\n",
    "    n_epochs = 20\n",
    "    threshold = 0.5\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=5,\n",
    "        path=None,\n",
    "        verbose=False,\n",
    "        trace_func=print_n_log.run('early_stopping', logf_path, 'DEBUG')\n",
    "    )\n",
    "                         \n",
    "    train_losses, val_losses = [], []\n",
    "    # training\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_train_losses, epoch_val_losses = [], []\n",
    "                         \n",
    "        model.train()\n",
    "        for ids, sentences, labels, features in train_loader:\n",
    "            labels = labels.float().to(device)\n",
    "            features = features.to(device)\n",
    "\n",
    "            embeddings = embedding_model.encode(sentences, convert_to_tensor=True)\n",
    "            output = model(embeddings, sent_level_features=features)\n",
    "#             output = pair_model((embeddings,), features)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "                         \n",
    "            epoch_train_losses.append(loss.item())\n",
    "                         \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        y_pred, y_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for val_ids, val_sentences, val_labels, val_features in val_loader:\n",
    "                val_labels = val_labels.float().to(device)\n",
    "                val_features = val_features.to(device)\n",
    "\n",
    "                val_embeddings = embedding_model.encode(val_sentences, convert_to_tensor=True)\n",
    "                pred = model(val_embeddings, sent_level_features=val_features)\n",
    "#                 pred = pair_model((val_embeddings,), val_features)\n",
    "                val_loss = criterion(pred, val_labels)\n",
    "                epoch_val_losses.append(val_loss.item())\n",
    "\n",
    "                pred = torch.sigmoid(pred)\n",
    "\n",
    "                pred = (pred > threshold).int()\n",
    "                y_pred.extend(pred.tolist())\n",
    "                y_true.extend(val_labels.tolist())\n",
    "        \n",
    "        val_losses.append(np.average(epoch_val_losses))\n",
    "        train_losses.append(np.average(epoch_train_losses))\n",
    "        avg_val_loss = np.average(val_losses)\n",
    "\n",
    "        cr = classification_report(y_true, y_pred, output_dict=True, digits=6, zero_division=0)\n",
    "        # recall_p = cr['1.0']['recall']\n",
    "        # print(recall_p)\n",
    "        val_loss = np.average(val_losses)\n",
    "        early_stopping(val_loss, model, acomp_metrics={'f1_p': cr['1.0']['f1-score']})\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "        # trial.report(recall_p, epoch)\n",
    "\n",
    "        # # Handle pruning based on the intermediate value.\n",
    "        # if trial.should_prune():\n",
    "        #     raise optuna.exceptions.TrialPruned()\n",
    "    metric = early_stopping.acomp_metrics['f1_p'] if early_stopping.acomp_metrics else 0.0\n",
    "    \"Done.\"\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()\n",
    "# print('final recall: ', objective(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-21 13:49:23,187]\u001b[0m A new study created in memory with name: sent_nn_NO_FEAT_V2_mF1_sTPE_pNone_df0.2_wf0.03\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 13:51:17,523]\u001b[0m Trial 0 finished with value: 0.13471502590673576 and parameters: {'batch_size': 128, 'dropout': 0.3, 'learning_rate': 0.0005886157168501587, 'optimizer_weigth_decay': 0.021400292062309003, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 0 with value: 0.13471502590673576.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 13:51:49,572]\u001b[0m Trial 1 finished with value: 0.04862236628849271 and parameters: {'batch_size': 16, 'dropout': 0.15, 'learning_rate': 2.0357322724539077e-05, 'optimizer_weigth_decay': 9.255071851582603e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 0 with value: 0.13471502590673576.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 13:54:35,538]\u001b[0m Trial 2 finished with value: 0.09852216748768473 and parameters: {'batch_size': 16, 'dropout': 0.34, 'learning_rate': 3.441883561577144e-05, 'optimizer_weigth_decay': 0.004147845775226498, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 0 with value: 0.13471502590673576.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 13:56:16,055]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'batch_size': 64, 'dropout': 0.48, 'learning_rate': 0.033274731274846835, 'optimizer_weigth_decay': 0.02117332487795751, 'pos_weight': 1.0, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 0 with value: 0.13471502590673576.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 13:57:05,272]\u001b[0m Trial 4 finished with value: 0.07364341085271317 and parameters: {'batch_size': 128, 'dropout': 0.19, 'learning_rate': 0.00042744799652375546, 'optimizer_weigth_decay': 2.340792609442497e-06, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 0 with value: 0.13471502590673576.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 13:57:52,537]\u001b[0m Trial 5 finished with value: 0.10725552050473186 and parameters: {'batch_size': 128, 'dropout': 0.22, 'learning_rate': 0.010365958508184565, 'optimizer_weigth_decay': 0.0017325335768844968, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 0 with value: 0.13471502590673576.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 13:58:43,359]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'batch_size': 32, 'dropout': 0.32, 'learning_rate': 1.8836493114264886e-05, 'optimizer_weigth_decay': 6.376595576393632e-06, 'pos_weight': 1.0, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 0 with value: 0.13471502590673576.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:01:25,566]\u001b[0m Trial 7 finished with value: 0.1568627450980392 and parameters: {'batch_size': 32, 'dropout': 0.29, 'learning_rate': 0.00021949580221859786, 'optimizer_weigth_decay': 4.557177618331748e-06, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 7 with value: 0.1568627450980392.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:02:42,256]\u001b[0m Trial 8 finished with value: 0.07329842931937174 and parameters: {'batch_size': 64, 'dropout': 0.47000000000000003, 'learning_rate': 1.4419450771689446e-05, 'optimizer_weigth_decay': 6.3013062435074846e-06, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 7 with value: 0.1568627450980392.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:05:05,770]\u001b[0m Trial 9 finished with value: 0.16766467065868265 and parameters: {'batch_size': 32, 'dropout': 0.04, 'learning_rate': 0.0036775164933834474, 'optimizer_weigth_decay': 0.0001186190666095454, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:07:30,765]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'batch_size': 32, 'dropout': 0.0, 'learning_rate': 0.004081211259649806, 'optimizer_weigth_decay': 9.975114025392612e-05, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:09:54,600]\u001b[0m Trial 11 finished with value: 0.10370370370370371 and parameters: {'batch_size': 32, 'dropout': 0.05, 'learning_rate': 0.00016543606763037586, 'optimizer_weigth_decay': 3.3254676671753424e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:12:19,729]\u001b[0m Trial 12 finished with value: 0.16279069767441862 and parameters: {'batch_size': 32, 'dropout': 0.1, 'learning_rate': 0.0022784543129779483, 'optimizer_weigth_decay': 0.0006771532572264492, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:14:43,868]\u001b[0m Trial 13 finished with value: 0.16666666666666669 and parameters: {'batch_size': 32, 'dropout': 0.09, 'learning_rate': 0.002800860629957816, 'optimizer_weigth_decay': 0.000903589455918254, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:15:51,175]\u001b[0m Trial 14 finished with value: 0.15841584158415842 and parameters: {'batch_size': 32, 'dropout': 0.1, 'learning_rate': 0.06086870101756789, 'optimizer_weigth_decay': 0.0003206193434747105, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:18:16,004]\u001b[0m Trial 15 finished with value: 0.0 and parameters: {'batch_size': 32, 'dropout': 0.0, 'learning_rate': 0.011239941003362092, 'optimizer_weigth_decay': 0.003942037603590827, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:20:39,131]\u001b[0m Trial 16 finished with value: 0.1090909090909091 and parameters: {'batch_size': 32, 'dropout': 0.1, 'learning_rate': 0.0016799709756154407, 'optimizer_weigth_decay': 0.07709670749974204, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:21:20,645]\u001b[0m Trial 17 finished with value: 0.15384615384615383 and parameters: {'batch_size': 64, 'dropout': 0.15, 'learning_rate': 0.009343513174969913, 'optimizer_weigth_decay': 5.851768271053917e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:23:47,534]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'batch_size': 16, 'dropout': 0.05, 'learning_rate': 0.004491211030466088, 'optimizer_weigth_decay': 2.1534276778422458e-05, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:26:12,319]\u001b[0m Trial 19 finished with value: 0.13930348258706468 and parameters: {'batch_size': 32, 'dropout': 0.41000000000000003, 'learning_rate': 0.0010117770297390944, 'optimizer_weigth_decay': 0.00033133010204040934, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:27:58,051]\u001b[0m Trial 20 finished with value: 0.15165876777251183 and parameters: {'batch_size': 32, 'dropout': 0.05, 'learning_rate': 0.029112778050072497, 'optimizer_weigth_decay': 0.0014631218249433894, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 9 with value: 0.16766467065868265.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:30:22,156]\u001b[0m Trial 21 finished with value: 0.16867469879518074 and parameters: {'batch_size': 32, 'dropout': 0.1, 'learning_rate': 0.0025873783785793887, 'optimizer_weigth_decay': 0.0008505328927323808, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:32:47,482]\u001b[0m Trial 22 finished with value: 0.16455696202531644 and parameters: {'batch_size': 32, 'dropout': 0.15, 'learning_rate': 0.003827303630240674, 'optimizer_weigth_decay': 0.00018289061876686726, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:35:11,010]\u001b[0m Trial 23 finished with value: 0.14507772020725387 and parameters: {'batch_size': 32, 'dropout': 0.07, 'learning_rate': 0.0012254279442306774, 'optimizer_weigth_decay': 0.0011198929894263197, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:37:35,409]\u001b[0m Trial 24 finished with value: 0.11255411255411256 and parameters: {'batch_size': 32, 'dropout': 0.19, 'learning_rate': 0.0004687430811017726, 'optimizer_weigth_decay': 0.0006851774249570852, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:38:11,285]\u001b[0m Trial 25 finished with value: 0.14736842105263157 and parameters: {'batch_size': 32, 'dropout': 0.24, 'learning_rate': 0.017686409796250073, 'optimizer_weigth_decay': 0.0051045315122144694, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:40:55,738]\u001b[0m Trial 26 finished with value: 0.0 and parameters: {'batch_size': 16, 'dropout': 0.02, 'learning_rate': 0.005609437772447224, 'optimizer_weigth_decay': 1.7538433171032657e-05, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:42:03,567]\u001b[0m Trial 27 finished with value: 0.0707395498392283 and parameters: {'batch_size': 64, 'dropout': 0.12, 'learning_rate': 9.337584731854032e-05, 'optimizer_weigth_decay': 0.00018693817020018854, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:43:54,730]\u001b[0m Trial 28 finished with value: 0.12682926829268293 and parameters: {'batch_size': 128, 'dropout': 0.2, 'learning_rate': 0.0022988488695165565, 'optimizer_weigth_decay': 0.007304963312465523, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:44:35,208]\u001b[0m Trial 29 finished with value: 0.136986301369863 and parameters: {'batch_size': 128, 'dropout': 0.07, 'learning_rate': 0.0007230182299176006, 'optimizer_weigth_decay': 0.014275255086503394, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:47:22,749]\u001b[0m Trial 30 finished with value: 0.12598425196850394 and parameters: {'batch_size': 32, 'dropout': 0.13, 'learning_rate': 0.00029889411662178034, 'optimizer_weigth_decay': 0.05680618388971344, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:50:09,190]\u001b[0m Trial 31 finished with value: 0.16470588235294117 and parameters: {'batch_size': 32, 'dropout': 0.16, 'learning_rate': 0.002535314521156451, 'optimizer_weigth_decay': 0.00024674157131501014, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:52:54,707]\u001b[0m Trial 32 finished with value: 0.16568047337278108 and parameters: {'batch_size': 32, 'dropout': 0.18, 'learning_rate': 0.0026390055480445683, 'optimizer_weigth_decay': 0.0006367935507196884, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:55:26,562]\u001b[0m Trial 33 finished with value: 0.16049382716049385 and parameters: {'batch_size': 32, 'dropout': 0.08, 'learning_rate': 0.007644435499098292, 'optimizer_weigth_decay': 0.0006290665471002625, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:58:19,890]\u001b[0m Trial 34 finished with value: 0.1435897435897436 and parameters: {'batch_size': 16, 'dropout': 0.28, 'learning_rate': 0.0007978872682049454, 'optimizer_weigth_decay': 0.0027682787735729417, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 14:59:52,560]\u001b[0m Trial 35 finished with value: 0.152046783625731 and parameters: {'batch_size': 32, 'dropout': 0.03, 'learning_rate': 0.023431374952902845, 'optimizer_weigth_decay': 7.713392383905961e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:01:47,636]\u001b[0m Trial 36 finished with value: 0.1340782122905028 and parameters: {'batch_size': 32, 'dropout': 0.18, 'learning_rate': 0.0011907783968513265, 'optimizer_weigth_decay': 0.0004897961761363209, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:02:28,326]\u001b[0m Trial 37 finished with value: 0.0 and parameters: {'batch_size': 128, 'dropout': 0.12, 'learning_rate': 0.015017375235221769, 'optimizer_weigth_decay': 0.001386061555339195, 'pos_weight': 1.0, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:03:29,008]\u001b[0m Trial 38 finished with value: 0.1256544502617801 and parameters: {'batch_size': 64, 'dropout': 0.25, 'learning_rate': 0.003281002055700782, 'optimizer_weigth_decay': 0.00013925233391393673, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:05:36,441]\u001b[0m Trial 39 finished with value: 0.16 and parameters: {'batch_size': 16, 'dropout': 0.23, 'learning_rate': 0.006520639375362158, 'optimizer_weigth_decay': 4.64208024388101e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:06:45,214]\u001b[0m Trial 40 finished with value: 0.06168831168831168 and parameters: {'batch_size': 32, 'dropout': 0.17, 'learning_rate': 4.39446304324686e-05, 'optimizer_weigth_decay': 0.01172743029155884, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:09:31,403]\u001b[0m Trial 41 finished with value: 0.1564245810055866 and parameters: {'batch_size': 32, 'dropout': 0.16, 'learning_rate': 0.002119644237049447, 'optimizer_weigth_decay': 0.0024150264009959593, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:12:17,353]\u001b[0m Trial 42 finished with value: 0.16867469879518074 and parameters: {'batch_size': 32, 'dropout': 0.13, 'learning_rate': 0.002856031267970771, 'optimizer_weigth_decay': 0.00025883463391595705, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:15:03,794]\u001b[0m Trial 43 finished with value: 0.14893617021276598 and parameters: {'batch_size': 32, 'dropout': 0.21, 'learning_rate': 0.0014594362717594994, 'optimizer_weigth_decay': 0.0008461548545222735, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:16:05,701]\u001b[0m Trial 44 finished with value: 0.12318840579710143 and parameters: {'batch_size': 32, 'dropout': 0.13, 'learning_rate': 0.005681816541931316, 'optimizer_weigth_decay': 0.000436588725531109, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:18:52,013]\u001b[0m Trial 45 finished with value: 0.0 and parameters: {'batch_size': 32, 'dropout': 0.09, 'learning_rate': 0.0033840147664584764, 'optimizer_weigth_decay': 0.0001402472253360387, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:21:37,248]\u001b[0m Trial 46 finished with value: 0.11926605504587155 and parameters: {'batch_size': 32, 'dropout': 0.03, 'learning_rate': 0.000525368973233764, 'optimizer_weigth_decay': 0.0022877112605795887, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:24:24,870]\u001b[0m Trial 47 finished with value: 0.14130434782608695 and parameters: {'batch_size': 32, 'dropout': 0.11, 'learning_rate': 0.0015751772307814004, 'optimizer_weigth_decay': 1.5551261305000225e-06, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:25:09,058]\u001b[0m Trial 48 finished with value: 0.16249999999999998 and parameters: {'batch_size': 64, 'dropout': 0.37, 'learning_rate': 0.009742101873013281, 'optimizer_weigth_decay': 9.964934776169801e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:27:02,762]\u001b[0m Trial 49 finished with value: 0.0 and parameters: {'batch_size': 128, 'dropout': 0.06, 'learning_rate': 0.0030074117222675034, 'optimizer_weigth_decay': 0.00032183928619227087, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:28:27,133]\u001b[0m Trial 50 finished with value: 0.14444444444444443 and parameters: {'batch_size': 32, 'dropout': 0.14, 'learning_rate': 0.05341815407446322, 'optimizer_weigth_decay': 1.4211959475967291e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:31:13,075]\u001b[0m Trial 51 finished with value: 0.15469613259668508 and parameters: {'batch_size': 32, 'dropout': 0.17, 'learning_rate': 0.0023475719107284264, 'optimizer_weigth_decay': 0.00020980714973352772, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:34:03,477]\u001b[0m Trial 52 finished with value: 0.16249999999999998 and parameters: {'batch_size': 32, 'dropout': 0.26, 'learning_rate': 0.004765001168743994, 'optimizer_weigth_decay': 0.0010301143610179152, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:36:50,213]\u001b[0m Trial 53 finished with value: 0.16470588235294117 and parameters: {'batch_size': 32, 'dropout': 0.09, 'learning_rate': 0.0019039095215263313, 'optimizer_weigth_decay': 0.00031071071021234717, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:39:22,563]\u001b[0m Trial 54 finished with value: 0.16867469879518074 and parameters: {'batch_size': 32, 'dropout': 0.01, 'learning_rate': 0.0028700892055184253, 'optimizer_weigth_decay': 2.9424380230861372e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 21 with value: 0.16867469879518074.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:41:45,545]\u001b[0m Trial 55 finished with value: 0.17073170731707316 and parameters: {'batch_size': 32, 'dropout': 0.02, 'learning_rate': 0.004200830479950449, 'optimizer_weigth_decay': 4.164846777394282e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:43:37,855]\u001b[0m Trial 56 finished with value: 0.16666666666666669 and parameters: {'batch_size': 32, 'dropout': 0.0, 'learning_rate': 0.008050155306408202, 'optimizer_weigth_decay': 3.188876644990673e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:44:32,329]\u001b[0m Trial 57 finished with value: 0.13124999999999998 and parameters: {'batch_size': 32, 'dropout': 0.0, 'learning_rate': 0.09712011422684629, 'optimizer_weigth_decay': 1.0563879710591093e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:45:41,078]\u001b[0m Trial 58 finished with value: 0.14035087719298245 and parameters: {'batch_size': 16, 'dropout': 0.03, 'learning_rate': 0.012685190413622994, 'optimizer_weigth_decay': 3.272400452158414e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:48:07,174]\u001b[0m Trial 59 finished with value: 0.16969696969696968 and parameters: {'batch_size': 32, 'dropout': 0.01, 'learning_rate': 0.00660815313329115, 'optimizer_weigth_decay': 2.9437787483903664e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:50:54,582]\u001b[0m Trial 60 finished with value: 0.0 and parameters: {'batch_size': 32, 'dropout': 0.02, 'learning_rate': 0.004474977438407705, 'optimizer_weigth_decay': 2.9984229184772483e-06, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:53:42,915]\u001b[0m Trial 61 finished with value: 0.15384615384615385 and parameters: {'batch_size': 32, 'dropout': 0.01, 'learning_rate': 0.006513588037364832, 'optimizer_weigth_decay': 2.9769977540411972e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:56:01,410]\u001b[0m Trial 62 finished with value: 0.1688311688311688 and parameters: {'batch_size': 32, 'dropout': 0.05, 'learning_rate': 0.008940290028502239, 'optimizer_weigth_decay': 5.749589669072847e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:57:10,825]\u001b[0m Trial 63 finished with value: 0.14018691588785046 and parameters: {'batch_size': 32, 'dropout': 0.05, 'learning_rate': 0.021409746489432644, 'optimizer_weigth_decay': 6.065304796649897e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 15:58:43,705]\u001b[0m Trial 64 finished with value: 0.1368421052631579 and parameters: {'batch_size': 32, 'dropout': 0.04, 'learning_rate': 0.012413693556068745, 'optimizer_weigth_decay': 1.116405951595487e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:00:56,119]\u001b[0m Trial 65 finished with value: 0.16666666666666669 and parameters: {'batch_size': 64, 'dropout': 0.07, 'learning_rate': 0.0036094745595465823, 'optimizer_weigth_decay': 5.171521068034119e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:01:47,517]\u001b[0m Trial 66 finished with value: 0.13930348258706468 and parameters: {'batch_size': 32, 'dropout': 0.05, 'learning_rate': 0.0009167695019326551, 'optimizer_weigth_decay': 7.280363388402298e-06, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:04:35,916]\u001b[0m Trial 67 finished with value: 0.17073170731707316 and parameters: {'batch_size': 32, 'dropout': 0.02, 'learning_rate': 0.00488554747921621, 'optimizer_weigth_decay': 2.254714553982529e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:06:46,440]\u001b[0m Trial 68 finished with value: 0.16470588235294117 and parameters: {'batch_size': 32, 'dropout': 0.02, 'learning_rate': 0.00835370580070705, 'optimizer_weigth_decay': 1.9114167345526596e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:09:34,749]\u001b[0m Trial 69 finished with value: 0.13071895424836602 and parameters: {'batch_size': 32, 'dropout': 0.07, 'learning_rate': 0.004989248791847688, 'optimizer_weigth_decay': 2.3869495105024014e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:11:28,858]\u001b[0m Trial 70 finished with value: 0.1293532338308458 and parameters: {'batch_size': 128, 'dropout': 0.01, 'learning_rate': 0.001702127509095131, 'optimizer_weigth_decay': 4.8934668158166484e-06, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:14:17,965]\u001b[0m Trial 71 finished with value: 0.15853658536585366 and parameters: {'batch_size': 32, 'dropout': 0.03, 'learning_rate': 0.004325720242286559, 'optimizer_weigth_decay': 7.779583928387524e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:16:56,640]\u001b[0m Trial 72 finished with value: 0.17073170731707316 and parameters: {'batch_size': 32, 'dropout': 0.04, 'learning_rate': 0.006555968339068866, 'optimizer_weigth_decay': 4.392720795604392e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:19:29,260]\u001b[0m Trial 73 finished with value: 0.15286624203821655 and parameters: {'batch_size': 32, 'dropout': 0.06, 'learning_rate': 0.006494576028204691, 'optimizer_weigth_decay': 4.0885935556015435e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:20:54,612]\u001b[0m Trial 74 finished with value: 0.13714285714285715 and parameters: {'batch_size': 32, 'dropout': 0.04, 'learning_rate': 0.017345379476940037, 'optimizer_weigth_decay': 1.4276340898121484e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:21:56,718]\u001b[0m Trial 75 finished with value: 0.12955465587044535 and parameters: {'batch_size': 32, 'dropout': 0.01, 'learning_rate': 0.03307427792316501, 'optimizer_weigth_decay': 6.762926311351273e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:23:05,937]\u001b[0m Trial 76 finished with value: 0.09059233449477352 and parameters: {'batch_size': 32, 'dropout': 0.08, 'learning_rate': 0.010046918731383777, 'optimizer_weigth_decay': 7.682004453640541e-06, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:26:01,876]\u001b[0m Trial 77 finished with value: 0.1375661375661376 and parameters: {'batch_size': 16, 'dropout': 0.46, 'learning_rate': 0.0011854277280854305, 'optimizer_weigth_decay': 2.3560107513880724e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:28:49,389]\u001b[0m Trial 78 finished with value: 0.0 and parameters: {'batch_size': 32, 'dropout': 0.04, 'learning_rate': 0.013981060872175216, 'optimizer_weigth_decay': 0.00011018421107420648, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:29:41,032]\u001b[0m Trial 79 finished with value: 0.15476190476190477 and parameters: {'batch_size': 32, 'dropout': 0.11, 'learning_rate': 0.003121430800104582, 'optimizer_weigth_decay': 4.851585918051332e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:31:53,531]\u001b[0m Trial 80 finished with value: 0.16867469879518074 and parameters: {'batch_size': 64, 'dropout': 0.06, 'learning_rate': 0.007012981342269999, 'optimizer_weigth_decay': 0.00014271779004504224, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 55 with value: 0.17073170731707316.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:34:04,498]\u001b[0m Trial 81 finished with value: 0.1739130434782609 and parameters: {'batch_size': 64, 'dropout': 0.02, 'learning_rate': 0.00687658226159879, 'optimizer_weigth_decay': 0.00015098895105608427, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:36:00,458]\u001b[0m Trial 82 finished with value: 0.14285714285714282 and parameters: {'batch_size': 64, 'dropout': 0.06, 'learning_rate': 0.007622411873181504, 'optimizer_weigth_decay': 0.00014612333310672573, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:37:53,021]\u001b[0m Trial 83 finished with value: 0.1625 and parameters: {'batch_size': 64, 'dropout': 0.02, 'learning_rate': 0.005349451580456207, 'optimizer_weigth_decay': 8.062854443774664e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:39:40,480]\u001b[0m Trial 84 finished with value: 0.15384615384615385 and parameters: {'batch_size': 64, 'dropout': 0.1, 'learning_rate': 0.010434907034458762, 'optimizer_weigth_decay': 0.00022921666519035375, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:41:33,706]\u001b[0m Trial 85 finished with value: 0.16867469879518074 and parameters: {'batch_size': 64, 'dropout': 0.08, 'learning_rate': 0.006196591685316708, 'optimizer_weigth_decay': 0.0004415513799885103, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:42:38,594]\u001b[0m Trial 86 finished with value: 0.15294117647058825 and parameters: {'batch_size': 64, 'dropout': 0.0, 'learning_rate': 0.01821353540672876, 'optimizer_weigth_decay': 3.585731516452965e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:44:31,607]\u001b[0m Trial 87 finished with value: 0.15662650602409636 and parameters: {'batch_size': 64, 'dropout': 0.04, 'learning_rate': 0.006067408642031436, 'optimizer_weigth_decay': 0.00016696752892324788, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:46:24,686]\u001b[0m Trial 88 finished with value: 0.1739130434782609 and parameters: {'batch_size': 64, 'dropout': 0.08, 'learning_rate': 0.008034106298060093, 'optimizer_weigth_decay': 0.0001257113448310962, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:47:09,882]\u001b[0m Trial 89 finished with value: 0.11666666666666668 and parameters: {'batch_size': 64, 'dropout': 0.02, 'learning_rate': 0.010875463679830276, 'optimizer_weigth_decay': 9.190511696648311e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:49:05,951]\u001b[0m Trial 90 finished with value: 0.16867469879518074 and parameters: {'batch_size': 64, 'dropout': 0.0, 'learning_rate': 0.004031942231837135, 'optimizer_weigth_decay': 2.62534538281397e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:50:58,130]\u001b[0m Trial 91 finished with value: 0.16568047337278108 and parameters: {'batch_size': 64, 'dropout': 0.0, 'learning_rate': 0.003624600712228243, 'optimizer_weigth_decay': 2.511127492607036e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:52:49,968]\u001b[0m Trial 92 finished with value: 0.16666666666666669 and parameters: {'batch_size': 64, 'dropout': 0.09, 'learning_rate': 0.007968074498729659, 'optimizer_weigth_decay': 0.00011502765943223826, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:54:41,563]\u001b[0m Trial 93 finished with value: 0.15757575757575756 and parameters: {'batch_size': 64, 'dropout': 0.01, 'learning_rate': 0.004467471411567917, 'optimizer_weigth_decay': 5.849314355704564e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:56:33,784]\u001b[0m Trial 94 finished with value: 0.13836477987421383 and parameters: {'batch_size': 64, 'dropout': 0.03, 'learning_rate': 0.005408494333862645, 'optimizer_weigth_decay': 1.5642829539336382e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 16:58:09,396]\u001b[0m Trial 95 finished with value: 0.14507772020725387 and parameters: {'batch_size': 128, 'dropout': 0.08, 'learning_rate': 0.0027754286133079217, 'optimizer_weigth_decay': 0.00047436539485098766, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 17:00:03,108]\u001b[0m Trial 96 finished with value: 0.0 and parameters: {'batch_size': 64, 'dropout': 0.05, 'learning_rate': 0.007366551474262498, 'optimizer_weigth_decay': 0.0003671864023706506, 'pos_weight': 1.0, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 17:01:04,107]\u001b[0m Trial 97 finished with value: 0.13888888888888887 and parameters: {'batch_size': 16, 'dropout': 0.06, 'learning_rate': 0.026841818286719096, 'optimizer_weigth_decay': 3.8712682051679916e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 17:01:51,197]\u001b[0m Trial 98 finished with value: 0.1348314606741573 and parameters: {'batch_size': 32, 'dropout': 0.04, 'learning_rate': 0.0020545871727482273, 'optimizer_weigth_decay': 1.2061682103344466e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-MiniLM-L6-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n",
      "\u001b[32m[I 2022-04-21 17:03:34,140]\u001b[0m Trial 99 finished with value: 0.1456953642384106 and parameters: {'batch_size': 64, 'dropout': 0.31, 'learning_rate': 0.014781615598614633, 'optimizer_weigth_decay': 0.0002444659570904717, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}. Best is trial 81 with value: 0.1739130434782609.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "# feature_search_space = {\n",
    "#     'stopwords_type': ['wstop', 'wostop'],\n",
    "#     'from_selection': [True, False],\n",
    "# #     'pos_feature_type': ['sum', 'onehot', 'none'],\n",
    "#     'tag_feature_type': ['sum', 'onehot', 'none'],\n",
    "# #     'dep_feature_type': ['sum', 'onehot', 'none'],\n",
    "#     'word_count_feature_type': ['count_words', 'none'],\n",
    "# #     'word_level_feature_type': ['dep', 'triplet']\n",
    "# }\n",
    "# params = {\n",
    "#     'batch_size': 16,\n",
    "#     'dropout': 0.09,\n",
    "#     'hidden_dim': 128,\n",
    "#     'with_sequential_layer': False,\n",
    "#     'learning_rate': 0.03698629814522988,\n",
    "#     'optimizer_weigth_decay': 0.02355650972967366,\n",
    "#     'pos_weight': 4.0042918454935625,\n",
    "#     'embedding_model_name': 'all-mpnet-base-v2',\n",
    "#     'fnn_hidden_dim': 256,\n",
    "#     'fnn_n_hidden_layers': 4,\n",
    "#     'fnn_dropout': 0.12,\n",
    "#     'pnn_hidden_dim': 8,\n",
    "#     'pnn_dropout': 0.24\n",
    "# }\n",
    "\n",
    "# featOptimFeatModel\n",
    "# feature_combination_search_space = {\n",
    "#     'tag_feature': [True, False],\n",
    "#     'dep_feature': [True, False]\n",
    "# }\n",
    "# feature_params = {\n",
    "#     'stopwords_type': 'wstop',\n",
    "#     'from_selection': True,\n",
    "#     'word_count_feature_type': 'none',\n",
    "#     # after featOptimFeatModel\n",
    "#     'tag_feature': 'sum',\n",
    "#     'dep_feature': 'sum'\n",
    "# }\n",
    "# after featOptimSentFeat\n",
    "# feature_params = {\n",
    "#     'stopwords_type': 'wstop',\n",
    "#     'from_selection': False,\n",
    "#     'tag_feature_type': 'sum',\n",
    "#     'word_count_feature_type': 'count_words'\n",
    "# }\n",
    "# sent_nn_wFeatModel_fPosDep_mF1_sTP after 100 iterations\n",
    "# params = {'batch_size': 16, 'dropout': 0.28, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.0008128750160252116, 'optimizer_weigth_decay': 6.849545410012206e-05, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'multi-qa-mpnet-base-dot-v1', 'fnn_hidden_dim': 512, 'fnn_n_hidden_layers': 3, 'fnn_dropout': 0.14, 'pnn_hidden_dim': 32, 'pnn_dropout': 0.23}\n",
    "study = optuna.create_study(\n",
    "    study_name=f'sent_nn_NO_FEAT_V2_mF1_sTPE_pNone_df{dataset_frac}_wf{worthy_frac}',\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "#     sampler=optuna.samplers.GridSampler(feature_combination_search_space),\n",
    "    # pruner=optuna.pruners.MedianPruner(),\n",
    "    direction='maximize'\n",
    ")\n",
    "logf_path = p.join(LOG_DIR_PATH, f'{study.study_name}.log')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study_path = os.path.join(optim_path, f'{study.study_name}.pkl')\n",
    "torch.save(study, study_path)\n",
    "# torch.save(params, f'{os.path.join(optim_path, study.study_name)}_params.pkl')\n",
    "# torch.save(feature_params, f'{os.path.join(optim_path, study.study_name)}_featureParams.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.02, 'learning_rate': 0.00687658226159879, 'optimizer_weigth_decay': 0.00015098895105608427, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}\n",
      "FrozenTrial(number=81, values=[0.1739130434782609], datetime_start=datetime.datetime(2022, 4, 21, 16, 31, 53, 532476), datetime_complete=datetime.datetime(2022, 4, 21, 16, 34, 4, 497924), params={'batch_size': 64, 'dropout': 0.02, 'learning_rate': 0.00687658226159879, 'optimizer_weigth_decay': 0.00015098895105608427, 'pos_weight': 32.81159420289855, 'embedding_model_name': 'all-mpnet-base-v2'}, distributions={'batch_size': CategoricalDistribution(choices=(16, 32, 64, 128)), 'dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.01), 'learning_rate': LogUniformDistribution(high=0.1, low=1e-05), 'optimizer_weigth_decay': LogUniformDistribution(high=0.1, low=1e-06), 'pos_weight': CategoricalDistribution(choices=(1.0, 32.81159420289855)), 'embedding_model_name': CategoricalDistribution(choices=('all-mpnet-base-v2', 'all-MiniLM-L6-v2', 'multi-qa-mpnet-base-dot-v1'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=81, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "loaded_study = torch.load(study_path)\n",
    "\n",
    "print(loaded_study.best_trial.params)\n",
    "print(loaded_study.best_trial)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0566b9ebc7a58507829be3d77002d1a3a0910233c54c7888c127aa3b7af58774"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
