{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as p\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from definitions import *\n",
    "from dataset_helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load devset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    IS_MASTER\n",
    "except: \n",
    "    IS_MASTER = False\n",
    "\n",
    "if not IS_MASTER:\n",
    "    data = {}\n",
    "    \n",
    "    dev_path = p.join(PROC_DATA_DIR_PATH, 'dev')\n",
    "\n",
    "    data_paths = {\n",
    "        'dev': [p.join(dev_path, 'dev.tsv'), p.join(dev_path, 'dev_spacy.pkl')],\n",
    "        'test': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'test', 'test_combined.tsv'),\n",
    "            p.join(PROC_DATA_DIR_PATH, 'test', 'test_spacy.pkl')\n",
    "        ],\n",
    "        'train': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'train', 'train_combined.tsv'),\n",
    "            p.join(PROC_DATA_DIR_PATH, 'train', 'train_spacy.pkl')\n",
    "        ],\n",
    "        # 'val': [\n",
    "        #     p.join(POLIT_DATA_DIR_PATH, 'val', 'val_combined.tsv'),\n",
    "        #     p.join(PROC_DATA_DIR_PATH, 'val', 'val_spacy.pkl')\n",
    "        # ],\n",
    "    }\n",
    "\n",
    "    for dtype, dpaths in data_paths.items():\n",
    "        if p.exists(dpaths[1]):\n",
    "            data[dtype] = pd.read_pickle(dpaths[1])\n",
    "        else:\n",
    "            if dtype == 'dev' and not p.exists(dpaths[0]):\n",
    "                sample_development_set()\n",
    "\n",
    "            data[dtype] = pd.read_csv(dpaths[0], sep='\\t', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether embeddings data folder exists. If not, create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = p.join(PROC_DATA_DIR_PATH, 'embeddings')\n",
    "if not p.exists(embeddings_path):\n",
    "    os.mkdir(embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model.\n",
    "\n",
    "3 models to try:\n",
    "- `all-mpnet-base-v2`: best performance overall, slow\n",
    "- `multi-qa-mpnet-base-dot-v1`: tuned for semantic search, good performance, slow \n",
    "- `all-MiniLM-L6-v2`: smallest with moderately good performance, fast; **dev done with this due to it's speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.18k/1.18k [00:00<00:00, 359kB/s]\n",
      "Downloading: 100%|██████████| 10.1k/10.1k [00:00<00:00, 2.80MB/s]\n",
      "Downloading: 100%|██████████| 571/571 [00:00<00:00, 256kB/s]\n",
      "Downloading: 100%|██████████| 116/116 [00:00<00:00, 51.4kB/s]\n",
      "Downloading: 100%|██████████| 39.3k/39.3k [00:00<00:00, 125kB/s] \n",
      "Downloading: 100%|██████████| 349/349 [00:00<00:00, 188kB/s]\n",
      "Downloading: 100%|██████████| 438M/438M [10:39<00:00, 685kB/s]   \n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 24.2kB/s]\n",
      "Downloading: 100%|██████████| 239/239 [00:00<00:00, 102kB/s]\n",
      "Downloading: 100%|██████████| 466k/466k [00:01<00:00, 294kB/s]  \n",
      "Downloading: 100%|██████████| 363/363 [00:00<00:00, 184kB/s]\n",
      "Downloading: 100%|██████████| 13.1k/13.1k [00:00<00:00, 4.70MB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 400kB/s] \n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 86.2kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sentences from dataset splits.\n",
    "\n",
    "Models accept list of sentences to encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype, df in data.items():\n",
    "    sentences = df['content'].values\n",
    "    embeddings = model.encode(sentences)\n",
    "\n",
    "    embeddings_df = df.loc[:, ['id']].merge(pd.DataFrame(embeddings), left_index=True, right_index=True)\n",
    "    embeddings_df.to_pickle(p.join(embeddings_path, f'{dtype}_sent_emb_{model_name}.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create devframe with sentences ids and embeddings and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_df = dev.loc[:, ['id']].merge(pd.DataFrame(embeddings), left_index=True, right_index=True)\n",
    "\n",
    "# embeddings_df.to_csv(p.join(embeddings_path, f'dev_sent_emb_{model_name}.tsv'), sep='\\t', index=False)\n",
    "# embeddings_df.to_pickle(p.join(embeddings_path, f'dev_sent_emb_{model_name}.pkl'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0566b9ebc7a58507829be3d77002d1a3a0910233c54c7888c127aa3b7af58774"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv_dp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
