{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from definitions import *\n",
    "from dataset_helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global switches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    IS_MASTER\n",
    "except: \n",
    "    IS_MASTER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_MASTER:\n",
    "    data, embeddings, features = {}, {}, {}\n",
    "    emb_model = 'all-mpnet-base-v2'#'multi-qa-mpnet-base-dot-v1'#'all-MiniLM-L6-v2'\n",
    "    \n",
    "    dev_path = p.join(PROC_DATA_DIR_PATH, 'dev')\n",
    "    features_path = p.join(PROC_DATA_DIR_PATH, 'features')\n",
    "    embeddings_path = p.join(PROC_DATA_DIR_PATH, 'embeddings')\n",
    "\n",
    "    data_paths = {\n",
    "        'dev': [\n",
    "            p.join(dev_path, 'dev.tsv'),\n",
    "            p.join(dev_path, 'dev_spacy.pkl'),\n",
    "            p.join(embeddings_path, f'dev_sent_emb_{emb_model}.pkl'),\n",
    "            p.join(features_path, 'dev_stylometric_features.pkl'),\n",
    "        ],\n",
    "        'test': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'test', 'test_combined.tsv'),\n",
    "            p.join(PROC_DATA_DIR_PATH, 'test', 'test_spacy.pkl'),\n",
    "            p.join(embeddings_path, f'test_sent_emb_{emb_model}.pkl'),\n",
    "            p.join(features_path, 'test_stylometric_features.pkl'),\n",
    "\n",
    "        ],\n",
    "        'train': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'train', 'train_combined.tsv'),\n",
    "            p.join(PROC_DATA_DIR_PATH, 'train', 'train_spacy.pkl'),\n",
    "            p.join(embeddings_path, f'train_sent_emb_{emb_model}.pkl'),\n",
    "            p.join(features_path, 'train_stylometric_features.pkl')\n",
    "        ],\n",
    "        # 'val': [\n",
    "        #     p.join(POLIT_DATA_DIR_PATH, 'val', 'val_combined.tsv'),\n",
    "        #     p.join(PROC_DATA_DIR_PATH, 'val', 'val_spacy.pkl'),\n",
    "        #     p.join(embeddings_path, f'val_sent_emb_{emb_model}.pkl'),\n",
    "        #     p.join(features_path, 'val_stylometric_features.pkl'),\n",
    "        # ],\n",
    "    }\n",
    "\n",
    "    for dtype, dpaths in data_paths.items():\n",
    "        try:\n",
    "            data[dtype] = pd.read_pickle(dpaths[1])\n",
    "            embeddings[dtype] = pd.read_pickle(dpaths[2])\n",
    "            features[dtype] = pd.read_pickle(dpaths[3])\n",
    "        except Exception as e:\n",
    "            print(e.args)\n",
    "            exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat embeddings with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_specifier = 'wstop_count'\n",
    "# print(data)\n",
    "# df = data['train']\n",
    "# df['label'].describe()\n",
    "# df.loc[np.array(list(map(len, df['label'].values)))>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors = {}\n",
    "scaler = MinMaxScaler()\n",
    "# concat \n",
    "for dtype in data_paths:\n",
    "    emb = embeddings[dtype].iloc[:, 1:].values\n",
    "    # print(len(emb))\n",
    "    scaler.fit(emb)\n",
    "    emb_scaled = scaler.transform(emb)\n",
    "\n",
    "    feat = features[dtype]\n",
    "    feat_cols = []\n",
    "    for col in feat.columns:\n",
    "        if feature_specifier in col:\n",
    "            feat_cols.append(col)\n",
    "\n",
    "    # print(feat[feat_cols])\n",
    "    input_vectors[dtype] = np.concatenate((emb_scaled, feat[feat_cols].values), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "first_layer_size = input_vectors['train'].shape[1]\n",
    "print(first_layer_size)\n",
    "# first_layer_size, 600, 200, 20, 1\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(400,),\n",
    "    # validation_fraction=0.2,\n",
    "    max_iter=600,\n",
    "    # early_stopping=True\n",
    ")\n",
    "\n",
    "model.fit(input_vectors['train'], data['train']['label'].values)\n",
    "pred = model.predict(input_vectors['test']).astype(np.int64)\n",
    "\n",
    "# print(model.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "precision:  0.0\n",
      "acc:  0.9790058660080272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/icobx/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# pred = [int(x) for x in pred]\n",
    "# pred = pred.astype(np.int64)\n",
    "print(pred)\n",
    "print(data['test']['label'].values)\n",
    "print('precision: ', precision_score(data['test']['label'].values, pred))\n",
    "print('acc: ', model.score(input_vectors['test'], data['test']['label'].values))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0566b9ebc7a58507829be3d77002d1a3a0910233c54c7888c127aa3b7af58774"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv_dp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
