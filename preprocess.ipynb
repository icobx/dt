{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as p\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy as s\n",
    "\n",
    "from definitions import *\n",
    "from dataset_helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global switches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_pos = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy = s.load('en_core_web_lg') # en_core_web_trf for accuracy\n",
    "stopwords = (set(nltk.corpus.stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code only needs to be run once at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_debates()\n",
    "# create_validation_subset()\n",
    "# sample_development_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = p.join(POLIT_DATA_DIR_PATH, 'train')\n",
    "dev = pd.read_csv(p.join(train_path, 'dev.tsv'), sep='\\t', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply spacy to content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev['spacy'] = dev['content'].apply(lambda x: spacy(x)).values\n",
    "# dev['spacy_no_stop'] = dev['spacy'].apply(lambda x: [t for t in x if t not in stopwords])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tags analysis\n",
    "- `pos_` represents coarse-grained POS tag described [here](https://universaldependencies.org/u/pos/)\n",
    "- `tag_` represents fine-grained POS tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize pos and tag dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_pos:\n",
    "    pos_df = pd.DataFrame(\n",
    "        index=pd.MultiIndex.from_product(\n",
    "            [\n",
    "                ['worthy', 'unworthy'],\n",
    "                ['stop', 'nostop'],\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    tag_df = pd.DataFrame(\n",
    "        index=pd.MultiIndex.from_product(\n",
    "            [\n",
    "                ['worthy', 'unworthy'],\n",
    "                ['stop', 'nostop'],\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill pos and tag dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_pos:\n",
    "    for _, sent, label in dev[['spacy', 'label']].itertuples():\n",
    "        worthiness = 'worthy' if label == 1 else 'unworthy'\n",
    "\n",
    "        for t in sent:\n",
    "            # ignore punctuation\n",
    "            if t.is_punct:\n",
    "                continue\n",
    "\n",
    "            stop = 'stop' if t.is_stop else 'nostop'\n",
    "\n",
    "            if t.pos_ in pos_df.columns:\n",
    "                pos_df.loc[(worthiness, stop), t.pos_] += 1\n",
    "            else:\n",
    "                pos_df.loc[:, t.pos_] = 0\n",
    "                pos_df.loc[(worthiness, stop), t.pos_] = 1\n",
    "\n",
    "            if t.tag_ in tag_df.columns:\n",
    "                tag_df.loc[(worthiness, stop), t.tag_] += 1\n",
    "            else:\n",
    "                tag_df.loc[:, t.tag_] = 0\n",
    "                tag_df.loc[(worthiness, stop), t.tag_] = 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 PROPN   AUX   DET  ADJ  NOUN  ADV   ADP  PRON  VERB  PART  \\\n",
      "worthy   stop        0    49    64    3     3   20    79    75    24    20   \n",
      "         nostop     45     1     0   40   130    8     1     0    72     0   \n",
      "unworthy stop        6  1107  1371  174    42  672  1238  2076   740   594   \n",
      "         nostop    763     7     0  659  2034  214    26    18  1629     0   \n",
      "\n",
      "                 CCONJ  NUM  SCONJ  INTJ  SYM  X  SPACE  PUNCT  \n",
      "worthy   stop       27    7     17     0    0  0      0      0  \n",
      "         nostop      0    7      0     0    3  0      0      0  \n",
      "unworthy stop      589   61    259    38    0  2      0      6  \n",
      "         nostop      0   95      2    48   19  2      4      0  \n",
      "                 PROPN   AUX   DET  ADJ  NOUN  ADV   ADP  PRON  VERB  PART  \\\n",
      "worthy   stop       45    50    64   43   133   28    80    75    96    20   \n",
      "         nostop     45     1     0   40   130    8     1     0    72     0   \n",
      "unworthy stop        6  1107  1371  174    42  672  1238  2076   740   594   \n",
      "         nostop    763     7     0  659  2034  214    26    18  1629     0   \n",
      "\n",
      "                 CCONJ  NUM  SCONJ  INTJ  SYM  X  SPACE  PUNCT  \n",
      "worthy   stop       27   14     17     0    3  0      0      0  \n",
      "         nostop      0    7      0     0    3  0      0      0  \n",
      "unworthy stop      589   61    259    38    0  2      0      6  \n",
      "         nostop      0   95      2    48   19  2      4      0  \n"
     ]
    }
   ],
   "source": [
    "print(pos_df)\n",
    "pos_df.loc['worthy', 'stop'] = pos_df.loc['worthy', 'stop'] + pos_df.loc['worthy', 'nostop']\n",
    "print(pos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- POS feature could be represented by one hot encoding based on whether sentence contains given POS tag or not\n",
    "- or can be represented as a number concatenated from counts of POS tags in a sentence including zeroes for POS not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = dev.loc[0, 'content']\n",
    "# x = spacy(temp)\n",
    "# temp = dev[['id', 'content']]\n",
    "# temp['spacied'] = temp['content'].apply(lambda x: spacy(x))\n",
    "# # temp = ['tag_ | pos_ | dep_ | lemma_ | norm_']\n",
    "# # for t in x:\n",
    "# #     temp.append(f'{t.tag_} | {t.pos_} | {t.dep_} | {t.lemma_} | {t.norm_}')\n",
    "# print(temp.loc[0, 'spacied'][0].tag_)\n",
    "# [(i.text, i.pos_, i.) for i in x]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea5e23d039880bc686ade8058e8989fedf6ebdbf20722602aab0e72521f2eedd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
