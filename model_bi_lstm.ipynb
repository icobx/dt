{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as p\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from definitions import *\n",
    "from model_helper_functions import *\n",
    "from dataset_helper_functions import *\n",
    "from bi_lstm import BiLSTM\n",
    "from bert_embedding_model import BertEmbeddingModel\n",
    "from debates_dataset import DebatesDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    IS_MASTER\n",
    "except: \n",
    "    IS_MASTER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_MASTER:\n",
    "    data, features = {}, {}\n",
    "    \n",
    "    dev_path = p.join(PROC_DATA_DIR_PATH, 'dev')\n",
    "    features_path = p.join(PROC_DATA_DIR_PATH, 'features')\n",
    "\n",
    "    data_paths = {\n",
    "        'dev': [\n",
    "            p.join(dev_path, 'dev.tsv'),\n",
    "            # p.join(dev_path, 'dev_spacy.pkl'),\n",
    "            # p.join(features_path, 'dev_stylometric_features.pkl'),\n",
    "        ],\n",
    "        'test': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'test', 'test_combined.tsv'),\n",
    "            # p.join(PROC_DATA_DIR_PATH, 'test', 'test_spacy.pkl'),\n",
    "            # p.join(features_path, 'test_stylometric_features.pkl'),\n",
    "\n",
    "        ],\n",
    "        'train': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'train', 'train_combined.tsv'),\n",
    "            # p.join(PROC_DATA_DIR_PATH, 'train', 'train_spacy.pkl'),\n",
    "            # p.join(features_path, 'train_stylometric_features.pkl')\n",
    "        ],\n",
    "        'val': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'val', 'val_combined.tsv'),\n",
    "            # p.join(PROC_DATA_DIR_PATH, 'val', 'val_spacy.pkl'),\n",
    "            # p.join(features_path, 'val_stylometric_features.pkl'),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    for dtype, dpaths in data_paths.items():\n",
    "        try:\n",
    "            data[dtype] = pd.read_csv(dpaths[0], sep='\\t', index_col=False)\n",
    "        except Exception as e:\n",
    "            print(e.args)\n",
    "            exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove validation records from train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df, test_df, train_df, val_df = data.values()\n",
    "dev_df\n",
    "rs = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu\n",
    "train_worthy = train_df.loc[train_df['label'] == 1]\n",
    "val_worthy = train_worthy.iloc[250:, :]\n",
    "train_worthy = train_worthy.iloc[:250, :]\n",
    "train_unworthy = train_df.loc[train_df['label'] == 0].iloc[:len(train_worthy)*2, :]\n",
    "ratio = len(train_unworthy) / len(train_worthy)\n",
    "\n",
    "imbalanced_train = train_worthy.append(train_unworthy).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_worthy = val_df.loc[val_df['label'] == 1]\n",
    "val_unworthy = val_df.loc[val_df['label'] == 0].sample(n=len(val_worthy), random_state=rs, ignore_index=True)\n",
    "\n",
    "balanced_val = val_worthy.append(val_unworthy).sample(frac=1, random_state=rs, ignore_index=True)\n",
    "\n",
    "test_worthy = test_df.loc[test_df['label'] == 1]\n",
    "test_unworthy = test_df.loc[test_df['label'] == 0].sample(n=len(test_worthy), random_state=rs, ignore_index=True)\n",
    "\n",
    "balanced_test = test_worthy.append(test_unworthy).sample(frac=1, random_state=rs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap data in `DebatesDataset` class so that it can be passed to `DataLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "transform = None\n",
    "\n",
    "dd_train = DebatesDataset(data=dev_df, transform=transform)\n",
    "dd_val = DebatesDataset(data=balanced_val, transform=transform)\n",
    "dd_test = DebatesDataset(data=balanced_test, transform=transform)\n",
    "\n",
    "# sent_level_feature_dim = len(dd_train[0][3]) if not transform else len(dd_train[0][4])\n",
    "\n",
    "loader_train = DataLoader(dd_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "loader_val = DataLoader(dd_val, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "loader_test = DataLoader(dd_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model, optimizer and criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_model = BertEmbeddingModel(device=device)\n",
    "model = BiLSTM(\n",
    "    embedding_dim=embedding_model.dim,\n",
    "    sent_level_feature_dim=0\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "n_epochs = 5\n",
    "eval_period = len(loader_train) // 2\n",
    "best_val_loss = float(\"Inf\")\n",
    "exp_path = p.join(EXP_DIR_PATH, 'bi-lstm', 'test-bcewlogitsloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize running values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss, val_running_loss = 0.0, 0.0\n",
    "global_step = 0\n",
    "train_losses, val_losses, global_steps = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [20/200], Train Loss: 0.6551, Validation Loss: 0.6321\n",
      "Model saved to ==> /Users/icobx/Documents/skola/dp/code/dt/exp/bi-lstm/test-bcewlogitsloss/model.pt\n",
      "Model saved to ==> /Users/icobx/Documents/skola/dp/code/dt/exp/bi-lstm/test-bcewlogitsloss/metrics.pt\n",
      "Epoch [1/5], Step [40/200], Train Loss: 0.5582, Validation Loss: 0.5309\n",
      "Model saved to ==> /Users/icobx/Documents/skola/dp/code/dt/exp/bi-lstm/test-bcewlogitsloss/model.pt\n",
      "Model saved to ==> /Users/icobx/Documents/skola/dp/code/dt/exp/bi-lstm/test-bcewlogitsloss/metrics.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dx/kzks528913555h6584x5x4140000gn/T/ipykernel_31416/449567603.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/code/dt/bert_embedding_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# hidden states from all layers. See the documentation for more details:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# https://huggingface.co/transformers/model_doc/bert.html#bertmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             hidden_states = self.model(\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         )\n\u001b[0;32m--> 995\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 )\n\u001b[1;32m    581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         )\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skola/dp/venv_dp/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for ids, sentences, labels, features in loader_train:\n",
    "        # print(sentences, labels)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        embeddings, lengths = embedding_model(sentences)\n",
    "        output = model(embeddings, lengths)\n",
    "        output = torch.sigmoid(output)\n",
    "        # print(output)\n",
    "        output.requires_grad_(True)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update running values\n",
    "        running_loss += loss.item()\n",
    "        # print(loss.item())\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % eval_period == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_ids, val_sentences, val_labels, val_features in loader_val:\n",
    "                    val_labels = val_labels.float().to(device)\n",
    "                    val_embeddings, val_lengths = embedding_model(val_sentences)\n",
    "\n",
    "                    val_output = model(val_embeddings, val_lengths)\n",
    "                    # val_output = model(val_sentences)\n",
    "                    val_output = torch.sigmoid(val_output)\n",
    "                    loss = criterion(val_output, val_labels)\n",
    "                    val_running_loss += loss.item()\n",
    "\n",
    "            train_losses.append(running_loss / eval_period)\n",
    "            val_losses.append(val_running_loss / len(loader_val))\n",
    "            global_steps.append(global_step)\n",
    "\n",
    "            running_loss, val_running_loss = 0.0, 0.0\n",
    "\n",
    "\n",
    "            print(\n",
    "                f'Epoch [{epoch+1}/{n_epochs}], '\n",
    "                f'Step [{global_step}/{n_epochs*len(loader_train)}], '\n",
    "                f'Train Loss: {train_losses[-1]:.4f}, '\n",
    "                f'Validation Loss: {val_losses[-1]:.4f}'\n",
    "            )\n",
    "\n",
    "            # TODO: early stopping here ?\n",
    "            if val_losses[-1] < best_val_loss:\n",
    "                best_val_loss = val_losses[-1]\n",
    "                save_checkpoint(\n",
    "                    p.join(exp_path, 'model.pt'),\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    val_loss=best_val_loss\n",
    "                )\n",
    "                save_metrics(\n",
    "                    p.join(exp_path, 'metrics.pt'),\n",
    "                    train_loss_list=train_losses,\n",
    "                    val_loss_list=val_losses,\n",
    "                    global_steps_list=global_steps   \n",
    "                )\n",
    "              \n",
    "save_metrics(\n",
    "    p.join(exp_path, 'metrics.pt'),\n",
    "    train_loss_list=train_losses,\n",
    "    val_loss_list=val_losses,\n",
    "    global_steps_list=global_steps\n",
    ")\n",
    "\n",
    "# save_params(\n",
    "#     p.join(exp_path, 'params.pt'),\n",
    "#     params={}\n",
    "# )\n",
    "\"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking:\n",
      "[0.9991528987884521, 0.9990171194076538, 0.9990077614784241, 0.9979572296142578, 0.9978961944580078, 0.9977433681488037, 0.9966907501220703, 0.9961395859718323, 0.9959587454795837, 0.9938822984695435]\n",
      "Accuracy: 0.6727941176470589\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6975    0.6103    0.6510       136\n",
      "         1.0     0.6536    0.7353    0.6920       136\n",
      "\n",
      "    accuracy                         0.6728       272\n",
      "   macro avg     0.6755    0.6728    0.6715       272\n",
      "weighted avg     0.6755    0.6728    0.6715       272\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'worthy'), Text(0, 1.5, 'unworthy')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAk/0lEQVR4nO3dd5xU5dn/8c93FwsoXUGiwRJLHkOEWLAgiL0mGB+jMRrRGNFEE1Ps8QmJSYxGTdSfphDRYI0NxYoaAooVRFGxobFLU7Ah0q/fH+csDJtld2aYs7Nn+b59zWtnzjlz39cu67X3XOc+91FEYGZm+VFT7QDMzKw0TtxmZjnjxG1mljNO3GZmOePEbWaWM07cZmY548Rtq0xSW0l3SfpY0i2r0M6Rkh6oZGzVIOk+SYOrHYe1Xk7cqxFJ35H0lKS5kqanCWbXCjR9KNAd6BoR3yq3kYi4PiL2qUA8K5A0UFJIur3e9t7p9nFFtvMrSdc1dVxE7B8RI8oM16xJTtyrCUk/Ay4BziNJsj2BPwODKtD8xsDUiFhcgbay8j6ws6SuBdsGA1Mr1YES/n/KMudfstWApI7AucBJETEyIj6LiEURcVdEnJYes5akSyRNSx+XSFor3TdQ0ruSfi5pVjpaPzbd92vgl8Dh6Uj+uPojU0mbpCPbNunrYyS9LulTSW9IOrJg+yMF79tF0sS0BDNR0i4F+8ZJ+o2kR9N2HpC0XiM/hoXAHcC30/fXAocD19f7WV0q6R1Jn0iaJKl/un0/4OyC7/PZgjh+J+lRYB6wWbrt++n+v0i6raD9CySNkaRi//3M6nPiXj3sDKwN3N7IMb8AdgL6AL2BvsA5Bfs3ADoCGwLHAVdI6hwRQ0lG8TdFxLoRMbyxQCStA1wG7B8R7YFdgMkNHNcFuCc9tivwR+CeeiPm7wDHAt2ANYFTG+sbuAY4On2+LzAFmFbvmIkkP4MuwA3ALZLWjojR9b7P3gXv+S4wBGgPvFWvvZ8DX03/KPUn+dkNDq81YavAiXv10BX4oIlSxpHAuRExKyLeB35NkpDqLEr3L4qIe4G5wFZlxrMU6CWpbURMj4gXGjjmQODViLg2IhZHxI3Ay8DXC465OiKmRsTnwM0kCXelIuIxoIukrUgS+DUNHHNdRMxO+7wYWIumv89/RMQL6XsW1WtvHsnP8Y/AdcCPIuLdJtoza5QT9+phNrBeXaliJb7AiqPFt9Jty9qol/jnAeuWGkhEfEZSojgRmC7pHklfLiKeupg2LHg9o4x4rgVOBnangU8gkk6V9FJanvmI5FNGYyUYgHca2xkRTwKvAyL5A2O2Spy4Vw+PAwuAgxs5ZhrJScY6PfnvMkKxPgPaFbzeoHBnRNwfEXsDPUhG0X8vIp66mN4rM6Y61wI/BO5NR8PLpKWM04HDgM4R0Qn4mCThAqysvNFo2UPSSSQj92lp+2arxIl7NRARH5OcQLxC0sGS2klaQ9L+kv6QHnYjcI6k9dOTfL8k+WhfjsnAAEk90xOjZ9XtkNRd0qC01r2ApOSytIE27gW2TKcwtpF0OLA1cHeZMQEQEW8Au5HU9OtrDywmmYHSRtIvgQ4F+2cCm5Qyc0TSlsBvgaNISianS+pTXvRmCSfu1URar/0ZyQnH90k+3p9MMtMCkuTyFPAc8DzwdLqtnL4eBG5K25rEism2Jo1jGjCHJIn+oIE2ZgMHkZzcm00yUj0oIj4oJ6Z6bT8SEQ19mrgfGE0yRfAtYD4rlkHqLi6aLenppvpJS1PXARdExLMR8SrJzJRr62bsmJVDPrltZpYvHnGbmeWME7eZWYVJuiq9WG1KwbYukh6U9Gr6tXO6XZIuk/SapOckbdtU+07cZmaV9w9gv3rbzgTGRMQWwJj0NcD+wBbpYwjwl6Yad+I2M6uwiHiY5OR7oUFA3eJjI1g+PXcQcE0kngA6SerRWPuNXZBRVVucNtpnTe2/DD++b7VDsBZowJZdVnntl7ZfO7nonDN/8hUnkIyO6wyLiGFNvK17RExPn88gWewNkovKCmcvvZtum85KtNjEbWbWrEpY2DFN0k0l6sbeH5LKHpy6VGJmBiAV/yjPzLoSSPp1Vrr9PeCLBcdtRBNXCDtxm5lBMuIu9lGeO0nWgCf9Oqpg+9Hp7JKdgI8LSioNcqnEzAxWZSTdQFO6ERhIsrjbu8BQ4HzgZknHkVyZe1h6+L3AAcBrJIulHdtU+07cZmYANbUVayoijljJrj0bODaAk0pp34nbzAxWpQTS7Jy4zcygoqWSrDlxm5mBR9xmZrnjEbeZWc54xG1mljMVnFWSNSduMzPwiNvMLHdqXOM2M8sXj7jNzHLGs0rMzHLGJyfNzHLGpRIzs5xxqcTMLGc84jYzyxmPuM3McsYjbjOznPGsEjOznPGI28wsZ1zjNjPLGY+4zcxyxiNuM7Oc8YjbzCxfVOPEbWaWK3KpxMwsZ/KTt8nPZwMzswxJKvpRRFunSJoi6QVJP0m3dZH0oKRX06+dy43VidvMjMolbkm9gOOBvkBv4CBJmwNnAmMiYgtgTPq6LE7cZmZATU1N0Y8m/A/wZETMi4jFwEPAIcAgYER6zAjg4LJjLfeNZmatiop/SBoi6amCx5CClqYA/SV1ldQOOAD4ItA9Iqanx8wAupcbqk9OmplR2qySiBgGDFvJvpckXQA8AHwGTAaW1DsmJEW5sXrEbWZGZU9ORsTwiNguIgYAHwJTgZmSeqR99QBmlRurE7eZGRWfVdIt/dqTpL59A3AnMDg9ZDAwqtxYXSoxM6PiF+DcJqkrsAg4KSI+knQ+cLOk44C3gMPKbdyJ28wMUE3lEndE9G9g22xgz0q0n2nillQbEUuaPtLMrLrydMl71jXuVyVdKGnrjPsxM1sllaxxZy3rxN2b5GzqlZKeSOc+dsi4TzOz0pUwj7vaMk3cEfFpRPw9InYBzgCGAtMljUgvATUzaxHyNOLOvMYNHAgcC2wCXAxcD/QH7gW2zLJ/M7NitYSEXKysZ5W8CowFLoyIxwq23yppQMZ9m5kVrYg1SFqMrBP3NhExt6EdEfHjjPs2MytefgbcmSfutpJ+TFImWdZXRHwv437NzEriUslyo4DxwL+ot8iKmVlL4sS9XLuIOCPjPszMVlmeEnfW1fi7JR2QcR9mZqtMNSr6UW2ZjLglfQoESbn/bEkLSBZbEclStL4IpxHH9N+Yw/puRABTp8/ljJuf51ff3JpeG3VAEm++/xln3PQ88xa6+rQ6OfO4b7J223aoppba2lrO+dPV3HHd35j85HikGjp07MyxPzmHTl3Xr3aouZSnEXcmiTsi2mfR7uqge4e1OHrXjdn/wkdYsHgplx7Vm4P69OC8O19i7oIkUZ/19S9zVL+eDBv7RpWjteb2899dQfuOnZa93veQozj4qBMAGHPnzdz1z6v47kmuTpYjT4k701KJpDHFbLMVtakRa69RS22NaLtGLbM+mb8saQOsvUZN8nnGVntt262z7PmCBZ/nKvm0NKv9lZOS1gbWAdZLb0Ff9512ADbMos/WYuYnCxj+0Js89IvdWLBoKY9M/YBHps4G4PzDerHbl9fntZlz+f1dL1c5Umt+4pJfngISu+13MAP2OxiA26/5K4+PvY+27dbl1PMur26IeVb9fFy0rEbcJwBPAV8GJhU8RgEr/c0qvAHnx8/em1FoLVuHtm3Y8yvd2OP3D9HvN2Npu2Yt39i2BwBn3jyFfr8Zy39mfcaBvXtUOVJrbmf84a/836UjOOVXf2TsPbcxdcozAHzz6BP5w9Wj2HHgPvz77lurHGV+5WnEnUnijohLgc2B30bEZhGxafroHRErTdwRMSwito+I7Tv2Xj0no+yyRVfenfM5cz5bxOKlwQNTZrLtxp2X7V8acM/k6ez71bJvEG051blrNwA6dOrC13bejTemvrjC/h1325enHxtXhchah5oaFf2otsxq3OkNFA7Jqv3WavqH8+nTs2NSxwZ23rwr/5k1l55d2y07Zo+vdOM/739WrRCtChbM/5z58z5b9vzFZ55kw403Y+a0d5YdM/nJ8Wyw0cbVCjH38jTizvoCnDGS/hcYGRE+nVaEZ9/5mNHPz+SOn+zCkqXBi+99wk1PvMM1J/Zl3bXaIMHL0z5l6MgXqh2qNaNPPprDn393JgBLlixhx932odd2O/OX885ixntvoxrRdf0NOOqk06scaX61gHxcNGWZT9P53OuQXO7+OSXM497itNFO9PZfhh/ft9ohWAs0YMsuq5x2tzrj/qJzzisX7FvVNJ/piNvzuc0sL/I04s78Lu+SvgHUrb09LiLuzrpPM7NStYSTjsXK+g445wM7kNz1BuAUSf0i4qws+zUzK5UT93IHAH0iYimApBHAM4ATt5m1KC6VrKgTMCd93rEZ+jMzK1lLmOZXrKwT93nA05LGkcwoGQCcmXGfZmYlq2TilvRT4Pskqwo9T3LD9B7AP4GuJFeSfzciFpbTftbrcR8EXEUS5K3AzhFxU8Z9mpmVTCr+0Xg72hD4MbB9RPQCaoFvAxcAf4qIzYEPgePKjTXrxD08/foN4FLgCkmnZNynmVnJKnzJexuSe+62AdoB04E9SAawACOAg8uNNet53GMlPUwys2R34ETgKyRJ3MysxSilVCJpCDCkYNOwiBgGEBHvSboIeJvkwsMHSKoOH0XE4vT4d1mFlVKzng44huTKycdJbhq8Q0TMyrJPM7NylFLiTpP0sIbbUWdgELAp8BFwC7DfKgdYIOtSyXPAQqAXsA3QS1LbjPs0MytZBReZ2gt4IyLej4hFwEigH9ApLZ0AbAS8V26smSbuiPhpRAwgWSVwNnA1yV8gM7MWpVInJ0lKJDtJaqcky+8JvAiMBQ5NjxlMcn+CsmRdKjkZ6A9sB7xJMsNkfJZ9mpmVo1LTASPiSUm3Ak8Di0kuOhwG3AP8U9Jv023DV95K47Kex7028EdgUkFR3sysxankJe8RMRQYWm/z60BFlrfMelbJRVm2b2ZWKTm6cLJZLnk3M2vxfMm7mVnO5ChvO3GbmYFH3GZmuePEbWaWM76RgplZzuRowO3EbWYGLpWYmeVOjvJ202uVSDpFUgclhkt6WtI+zRGcmVlzqZGKflRbMYtMfS8iPgH2AToD3wXOzzQqM7NmVuEbKWSqmFJJXZQHANdGxAvKUzHIzKwILSAfF62YxD1J0gMki4KfJak9sDTbsMzMmleexqPFJO7jgD7A6xExT1JXkjsWm5m1GjnK2ytP3JK2rbdpszz9RTIzK4XIT35rbMR9cSP7guSOxWZmrUKrqHFHxO7NGYiZWTW1hNkixSpmHnc7SedIGpa+3kLSQdmHZmbWfFrbPO6rSe7Uvkv6+j3gt5lFZGZWBRW8WXDmikncX4qIPwCLACJiHuSoim9mVgRJRT+qrZjpgAsltSU5IYmkLwELMo3KzKyZtYB8XLRiEvdQYDTwRUnXA/2AY7IMysysudXmKHM3mbgj4kFJTwM7kZRITomIDzKPzMysGbWEEkixil3WdTdgV5JyyRrA7ZlFZGZWBTmaDdh04pb0Z2Bz4MZ00wmS9oqIkzKNzMysGbW2EfcewP9ERN3JyRHAC5lGZWbWzCqVtyVtBdxUsGkz4JfANen2TYA3gcMi4sNy+ihmOuBrQM+C119Mt5mZtRqVmg4YEa9ERJ+I6ANsB8wjKS+fCYyJiC2AMenrsjS2yNRdJDXt9sBLkiakr3cEJpTboZlZS1SbTZF7T+A/EfGWpEHAwHT7CGAccEY5jTZWKrmonAbNzPKolLQtaQgwpGDTsIgY1sCh32b5+cHuETE9fT4D6F56lInGFpl6qNxGzczyppQ1SNIk3VCiXkbSmsA3gLMaeH9IilJjrFPMIlM7SZooaa6khZKWSPqk3A7NzFqiDNYq2R94OiJmpq9nSuqR9KUewKxyYy3m5OTlwBHAq0Bb4PvAFeV2aGbWEmWwVskRLC+TANwJDE6fDwZGlRtrMYmbiHgNqI2IJRFxNbBfuR2ambVElRxxS1oH2BsYWbD5fGBvSa8Ce6Wvy1LMPO55aa1msqQ/ANMpMuGbmeVFJWeVRMRnQNd622aTzDJZZcUk4O+mx50MfEYyj/uQSnRuZtZStKplXSPirfTpfODXAJJuAg7PMC6e/72rMfbfOu9wcrVDsBbo82cuX+U28lRGKHaRqfp2rmgUZmZV1hJG0sUqN3GbmbUqrWJ1QEnbrmwXydKuZmatRkaXvGeisRH3xY3se7nSgZiZVVOO8najl7zv3pyBmJlVU45K3K5xm5lBaWuVVJsTt5kZq8d0QDOzViVHA+6i7jkp4Ehgs4g4V1JPYIOI8M0UzKzVyNOskmI+HfyZ5IKbI9LXn+LVAc2slalR8Y9qK6ZUsmNEbCvpGYCI+DBddMrMrNVobScnF0mqJbnfJJLWB5ZmGpWZWTPLUd4uKnFfRnKH4m6SfgccCpyTaVRmZs2sJZRAilXM6oDXS5pEso6sgIMj4qXMIzMza0Yq6XbB1VXMrJKewDzgrsJtEfF2loGZmTWnNjmayF1MqeQekvq2gLWBTYFXgK9kGJeZWbNqVcu6RsRXC1+nqwb+MLOIzMyqoFXVuOuLiKcl7ZhFMGZm1ZKjAXdRNe6fFbysAbYFpmUWkZlZFbS2edztC54vJql535ZNOGZm1VHbWk5OphfetI+IU5spHjOzqqhpDdMBJbWJiMWS+jVnQGZm1ZCjSkmjI+4JJPXsyZLuBG4BPqvbGREjM47NzKzZtLZZJWsDs4E9WD6fOwAnbjNrNSp5clJSJ+BKoBdJvvweyfUvNwGbAG8Ch0XEh+W031ji7pbOKJnC8oRdJ8rpzMyspapwqeRSYHREHJquptoOOBsYExHnSzoTOBM4o5zGG0vctcC60GDF3onbzFqVSt1IQVJHYABwDEBELAQWShoEDEwPGwGMI4PEPT0izi2nUTOzvCllNqCkIcCQgk3DImJY+nxT4H3gakm9gUnAKUD3iJieHjMD6F5urI0l7hyV6s3MVk0pa5WkSXrYSna3IZnY8aOIeFLSpSRlkcL3h6SyKxeN/ZHZs9xGzczyRiU8mvAu8G5EPJm+vpUkkc+U1AMg/Tqr3FhXmrgjYk65jZqZ5U2NVPSjMRExA3hH0lbppj2BF4E7gcHptsHAqHJjLXmRKTOz1qjCteEfAdenM0peB44lGSjfLOk44C3gsHIbd+I2MwNqKngFTkRMBrZvYFdFStBO3GZmlDarpNoyjVXSSEkHSsrTz8TMVkOSin5UW9YJ9c/Ad4BXJZ1fUKw3M2tRKjirJHOZJu6I+FdEHEkyFeZN4F+SHpN0rKQ1suzbzKwUHnEXkNSV5NLP7wPPkFzDvy3wYNZ9m5kVq1Yq+lFtmZ6clHQ7sBVwLfD1gss9b5L0VJZ9m5mVovrpuHhZzyq5LCLGNrQjIhqaKmNmVhUtYCBdtEwTd0SMlbQLyfqzbQq2X5Nlv2ZmpWoVty6rBEnXAl8CJgNL0s0BOHGbWYviEfdy2wNbR4TX7zazFk0ecS8zBdgAmN7UgWZm1dQSZosUK5PELekukpJIe+BFSROABXX7I+IbWfRrZlauHOXtzEbcF2XUrplZJlb7xB0RDwFIuiAiVrinmqQLgIey6NfMrFx5qnFnfeXk3g1s2z/jPs3MSlaj4h/VllWN+wfAD4EvSXquYFd74NEs+jQzWxVN3dmmJcmqxn0DcB/we1a8SeanviWambVEeSqVZFXj/ljSXOBrEfFWFn20VgsWLODYo49k0cKFLF6yhL332ZcfnvxjIoLLL7uEB+4fTW1tDd86/AiOPOroaodrGfrr0CPZf0Av3p/zKdt/6zwAOndox7UXfI+Nv9CFt6bN4ajTh/PRp58DcPHph7Jvv68wb/5Chgy9lskvv1vN8HOnJZRAipVZjTsilgCvSOqZVR+t0ZprrsmVV43gltvv5Obb7uDRR8bz3LOTGXXHSGbMmM6ou+/jjrvuY7/9D6x2qJaxa+96gkEnXbHCtlOP3ZtxE17hq4POZdyEVzj12H0A2HfXrflSz/XpNejXnPzbG7ns7G9XI+RcUwn/VVvWJyc7Ay9IGiPpzrpHxn3mmiTarbMOAIsXL2bx4sUgcfM/b+SEE0+ipib5J+vatWs1w7Rm8OjT/2HOx/NW2HbQwG247q4nAbjurif5+u7bJNt324Yb7p4AwITn36Rj+7ZssF6H5g0456TiH9WW9ZWT/5dx+63SkiVLOOJbh/D2229z+BHfYZttevPuO+9w/+h7+feYB+ncuQtnnH0OG2+8SbVDtWbWrWt7ZnzwCQAzPviEbl3bA/CFbp14d8aHy457b+ZHfKFbp2XHWtNaQD4uWtZ3wHkIeJlkNkl74KW6Od4NkTRE0lOSnhr+92FZhtai1dbWcvPIUTzw74eY8vxzvPrqVBYuXMiaa63FjTeP5JBDD2PoOWdXO0xrAbwKUOXk6UYKWd8s+DBgAvAt4DDgSUmHruz4iBgWEdtHxPbHHT8ky9ByoUOHDuzQd0cee2Q83Tfozp57JdPi99xrb16d+kqVo7NqmDX702UlkA3W68D7cz4FYNqsj9hog87LjtuweyemzfqoGiHmV45uOpl1jfsXwA4RMTgijgb64vJJo+bMmcMnnyQfb+fPn88Tjz/GJptuxu577MXECUlt86mJE1wmWU3d89DzHPX1HQE46us7cve455Zt/85BfQHo+9VN+GTu5y6TlChPJyezrnHXRMSsgtezaYb7XObZB+/P4pyzz2Tp0iUsXRrss+9+7DZwd7627XacfcapXHfNCNq1a8fQc39X7VAtYyN+fwz9t9uC9Tqty2ujf8Nv/novF139INdd8D0GH7wzb0+fw1GnXwXA6EdeYN9dv8ILdw5l3vxFnPCr66ocff60gApI0ZTlUtmSLgS2AW5MNx0OPFd//ZKGzF+Mq3f2XzrvcHK1Q7AW6PNnLl/ltDvx9Y+Lzjk7bNax0f4kvQl8SnIDmcURsb2kLsBNJHcEexM4LCI+XFkbjcn65ORpwN9Ikvc2wLBikraZWbOrfI1794joU3B/3TOBMRGxBTCGFa8qL0nWty47Dng4IkZm2Y+Z2apqhrVKBgED0+cjgHFAWQPZrOvNPYG/SXpd0i2SfiSpT8Z9mpmVrJQBd+HU5fRRfxpcAA9ImlSwr3tE1N0NbAbQvdxYs77L+1AASW2B44HTgEuA2iz7NTMrWQkD7ogYBjR2scmuEfGepG7Ag5Jervf+kFT2ebysSyXnAP2AdYFngFOB8Vn2aWZWjkpO84uI99KvsyTdTjIVeqakHhExXVIPYFajjTQi61LJIUBX4F/ASGBUwUcFM7MWo1JrlUhaR1L7uufAPiQ3Tr8TGJweNhgYVW6sWZdKtpXUgWTUvTcwTNKsiNg1y37NzEpVwXOT3YHblTTYBrghIkZLmgjcnE7aeIvkavKyZF0q6QX0B3YDtgfewaUSM2uBKlUqiYjXgd4NbJ8N7FmJPrK+cvJ8kkR9GTAxIhZl3J+ZWVnydOVk1qWSg7Js38ysUnKUtzMvlfQDfgVsnPYlkpkwm2XZr5lZyXKUubMulQwHfgpMIrlm38ysRWoJq/4VK+vE/XFE3JdxH2ZmqyxPNwvOOnGPTVcIHAksqNsYEU9n3K+ZWWmcuJfZMf26XfpVJNfw75Fxv2ZmJXGpZLlxDWzzOttm1uJ4OuBycwuerw0cBLyUcZ9mZiXLUd7OfB73xYWvJV0E3J9ln2ZmZclR5s56xF1fO2CjZu7TzKxJzXAjhYrJ+gKc51le064F1gfOzbJPM7Ny5CdtZz/iLrzkfTEwMyIWZ9ynmVnpcpS5s65xv5Vl+2ZmleLpgGZmOZOjErcTt5kZOHGbmeWOSyVmZjnjEbeZWc7kKG87cZuZgUfcZmY5lJ/M7cRtZoZvpGBmljsulZiZ5YynA5qZ5U1+8jY11Q7AzKwlUAmPotqTaiU9I+nu9PWmkp6U9JqkmyStWW6sTtxmZiQ17mIfRTqFFe/4dQHwp4jYHPgQOK7cWJ24zcwASUU/imhrI+BA4Mr0tUhukn5resgI4OByY3XiNjOjtFKJpCGSnip4DKnX3CXA6cDS9HVX4KOC+xG8C2xYbqw+OWlmRmnTASNiGDCs4XZ0EDArIiZJGliJ2Opz4jYzo6LTAfsB35B0ALA20AG4FOgkqU066t4IeK/cDlwqMTOjcicnI+KsiNgoIjYBvg38OyKOBMYCh6aHDQZGlRurE7eZGZnMKqnvDOBnkl4jqXkPL7chl0rMzMjmysmIGAeMS5+/DvStRLtO3GZmeK0SM7PcyVHeduI2MwNylbmduM3M8OqAZma54xspmJnljRO3mVm+uFRiZpYzeZoOqIiodgzWBElD0kVtzJbx78Xqy5e850P9JSPNwL8Xqy0nbjOznHHiNjPLGSfufHAd0xri34vVlE9OmpnljEfcZmY548RtZpYzTtw5IeknktoVvJ5bzXisZZPUSdIPC14PlHR3NWOyynHizgFJtcBPgHZNHGqGpDZAJ+CHTRxqOeXEnTFJp0n6cfr8T5L+nT7fQ9L1ko6Q9LykKZIuKHjfXEkXS3oW+AXwBWCspLEFx/xO0rOSnpDUXVJ7SW9IWiPd36HwtTU/SZtImlLw+lRJv5I0TtIFkiZImiqpf7r/HknbpM+fkfTL9Pm5ko5X4sL09+V5SYen+wdKGi/pTuBF4HzgS5ImS7ow7X5dSbdKejn93VP6e3hHQXx7S7q9WX44VjYn7uyNB/qnz7cn+Z9njXTbVOACYA+gD7CDpIPTY9cBnoyI3hFxLjAN2D0idi/Y/0RE9AYeBo6PiE9J7m93YHrMt4GREbEou2/PVkGbiOhL8mlqaLptPNBfUkdgMdAv3d6f5N/5EJLfld7AXsCFknqkx2wLnBIRWwJnAv+JiD4RcVq6/2tpX1sDm6VtjwW+LGn99Jhjgasq/p1aRTlxZ28SsJ2kDsAC4HGSBN4f+AgYFxHvR8Ri4HpgQPq+JcBtjbS7EKirWU4CNkmfX0nyPx/p16sr8l1YFkamXwv//caT/A70A+4h+UPfDtg0Il4BdgVujIglETETeAjYIX3vhIh4o5H+JkTEuxGxFJgMbBLJfOBrgaMkdQJ2Bu6r0PdnGfHqgBmLiEWS3gCOAR4DngN2BzYH3gS2W8lb50fEkkaaXhTLJ+EvIf23jIhH04/nA4HaiJiykvdb81jMigOktQueL0i/Lvv3AyaS/GF/HXgQWA84niS5N+WzJvYvKHhe2OfVwF3AfOCWdBBhLZhH3M1jPHAqyUfd8cCJwDPABGA3SeulJyCPIBlBNeRToH2R/V0D3IBH2y3BTKCbpK6S1gIOauzgiFgIvAN8i+TTWeHvDunrwyXVpuWNASS/R/UV/fsSEdNISnHn4N+ZXHDibh7jgR7A4+nH2/nA+IiYTlKLHAs8C0yKiFEraWMYMLrw5GQjrgc6AzeucuS2StLzC+eSJNcHgZeLeNt4YFZEfJ4+3yj9CnA7yae2Z4F/A6dHxIwG+p0NPJqexLyw/v4GXA+8ExEvFXGsVZkveW+FJB0KDIqI71Y7FssHSZcDz0TE8GrHYk1zjbuVkfT/gP2BA6odi+WDpEkk9fGfVzsWK45H3GZmOeMat5lZzjhxm5nljBO3mVnOOHHbCiQtSde3mCLplsIVCcto6x/pDBckXSlp60aOHShplzL6eFPSesVuX0kbx6SzKla5X7Pm4MRt9X2erm/Ri+Sy+hMLd6Yrz5UsIr4fES82cshAoOTEbbY6cuK2xowHNq+/8lx61d6FkiZKek7SCQDpanOXS3pF0r+AbnUNpavhbZ8+30/S0+nKhmMkbULyB+Kn6Wi/v6T1Jd2W9jFRUr/0vV0lPSDpBUlXAir2m5HUV9Lj6ap7j0naqmD3F9MYX5U0tOA9R6Ur+E2W9Lf0CtfCNtdJV/R7Nv2UcnipP2SzUnketzUoHVnvD4xON20L9IqINyQNAT6OiB3Sy7gflfQAyepzW5GsPtedZHnRq+q1uz7wd2BA2laXiJgj6a/A3Ii4KD3uBuBPEfGIpJ7A/cD/kKyi90hEnCvpQOC4Er6tl4H+EbFY0l7AecD/pvv6Ar2AecBESfeQzG0+HOiXrjnzZ+BIkiUF6uwHTIuIA9O4O5YQj1lZnLitvraSJqfPxwPDSUoYhSvP7QNsU1e/BjoCW5Csm3FjujjWNKVrj9ezE/BwXVsRMWclcewFbC0tG1B3kLRu2sch6XvvkfRhCd9bR2CEpC2AAArXKX8wvUwcSSNJVuFbTLII2MQ0jrbArHptPg9crGQt9bsjYjxmGXPitvo+j4g+hRvSpFW48pyAH0XE/fWOq+TVmjXAThExv4FYyvUbYGxEfDMtz4wr2Ff/SrQg+T5HRMRZK2swIqZK2pbkStXfShqTrp9ulhnXuK0c9wM/0PI77WwpaR2SFezqVq7rQbJ8bX1PAAMkbZq+t0u6vf5qdg8AP6p7IalP+vRh4Dvptv1JFtMqVkfgvfT5MfX27S2pi6S2wMHAo8AY4FBJ3epilbRx4ZskfQGYFxHXAReSlJTMMuURt5XjSpKF/59WMgR+nyTZ3U5yN58XgbdJliVdQUS8n9bIR0qqISk97E2yHvStkgaRJOwfA1dIeo7k9/RhkhOYvwZulPQCyfrmbzcS53OSlqbPbwb+QFIqOYfkJgWFJpDcuGIj4LqIeAogPfaBNNZFwEnAWwXv+yrJXWiWpvt/0Eg8ZhXhtUrMzHLGpRIzs5xx4jYzyxknbjOznHHiNjPLGSduM7OcceI2M8sZJ24zs5z5/wD7XMR2qpUiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_pred = []\n",
    "y_true = []\n",
    "temp = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for test_ids, test_sentences, test_labels, test_features in loader_test:           \n",
    "        test_labels = test_labels.float().to(device)\n",
    "\n",
    "        embeddings, lengths = embedding_model(test_sentences)\n",
    "        output = torch.sigmoid(model(embeddings, lengths))\n",
    "\n",
    "        temp.extend(output.tolist())\n",
    "        output = (output > threshold).int()\n",
    "        y_pred.extend(output.tolist())\n",
    "        y_true.extend(test_labels.tolist())\n",
    "\n",
    "print('Ranking:')\n",
    "temp.sort(reverse=True)\n",
    "print(temp[:10])\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n",
    "# print(f'precision: {tp/(tp+fp)}')\n",
    "# print(f'recall: {tp/(tp+fn)}')\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true, y_pred, digits=4)) # labels=[1,0], \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax=ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['worthy', 'unworthy'])\n",
    "ax.yaxis.set_ticklabels(['worthy', 'unworthy'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0566b9ebc7a58507829be3d77002d1a3a0910233c54c7888c127aa3b7af58774"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv_dp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
