{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os.path as p\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "import print_n_log\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from definitions import *\n",
    "from model_helper_functions import *\n",
    "from dataset_helper_functions import *\n",
    "from bi_lstm import BiLSTM\n",
    "from bert_embedding_model import BertEmbeddingModel\n",
    "from debates_dataset import DebatesDataset\n",
    "from early_stopping import EarlyStopping\n",
    "from optuna.trial import TrialState\n",
    "from torchvision import transforms\n",
    "# my transforms\n",
    "from transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "# optim_path = os.path.join(EXP_DIR_PATH, 'sent-nn', 'optimization')\n",
    "optim_path = os.path.join(EXP_DIR_PATH, 'bi-lstm', 'optimization')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_uw_ratio = 0\n",
    "dataset_frac = 0.2\n",
    "worthy_frac = 0.2\n",
    "rs = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dev_path = p.join(PROC_DATA_DIR_PATH, 'dev')\n",
    "\n",
    "    data_paths = {\n",
    "        'dev': [\n",
    "            p.join(dev_path, 'dev.tsv'),\n",
    "        ],\n",
    "        'test': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'test', 'test_combined.tsv'),\n",
    "        ],\n",
    "        'train': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'train', 'train_combined.tsv'),\n",
    "        ],\n",
    "        'val': [\n",
    "            p.join(POLIT_DATA_DIR_PATH, 'val', 'val_combined.tsv'),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    for dtype, dpaths in data_paths.items():\n",
    "        try:\n",
    "            data[dtype] = pd.read_csv(dpaths[0], sep='\\t', index_col=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e.args)\n",
    "            exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets and DataLoaders, takes trial as input to be able to suggest values for variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(trial):\n",
    "    global train_uw_ratio\n",
    "    # dev_df, test_df, train_df, val_df = data.values()\n",
    "    subsets = {}\n",
    "    for k, df in data.items():\n",
    "\n",
    "        n_subset = int(len(df)*dataset_frac)\n",
    "\n",
    "        worthy_df = df.loc[df['label'] == 1]\n",
    "        n_worthy = min(int(n_subset*worthy_frac), len(worthy_df))\n",
    "        worthy_df = worthy_df.sample(n=n_worthy, random_state=rs)\n",
    "\n",
    "        unworthy_df = df.loc[df['label'] == 0].sample(\n",
    "            n=n_subset-n_worthy,\n",
    "            random_state=rs\n",
    "        )\n",
    "        if k == 'train':\n",
    "            train_uw_ratio = len(unworthy_df) / len(worthy_df)\n",
    "        # sample(frac=1.0) -> shuffle\n",
    "        subsets[k] = worthy_df.append(unworthy_df).sample(frac=1.0, random_state=rs, ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    # transform_pipeline = transforms.Compose([\n",
    "    #     Sum('pos', stopwords='wostop'),\n",
    "    #     Sum('tag', stopwords='wostop'),\n",
    "    #     ToBinary(6),\n",
    "    #     ToTensor()\n",
    "    # ])\n",
    "    transform_pipeline = None\n",
    "\n",
    "    train_dd = DebatesDataset(data=subsets['train'], transform=transform_pipeline)\n",
    "    val_dd = DebatesDataset(data=subsets['val'], transform=transform_pipeline)\n",
    "    test_dd = DebatesDataset(data=subsets['test'], transform=transform_pipeline)\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "\n",
    "    train_loader = DataLoader(train_dd, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dd, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dd, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model setup + training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global logf_path\n",
    "    train_loader, val_loader, test_loader = get_loaders(trial)\n",
    "\n",
    "    # hyperparams opt\n",
    "    pooling_strategy = trial.suggest_categorical('pooling_strategy', ['last_four', 'last_four_sum', 'second_last'])\n",
    "    # should_scale_emb = trial.suggest_categorical('should_scale_emb', [True, False])\n",
    "#     pooling_strategy = 'second_last'\n",
    "    should_scale_emb = False\n",
    "    embedding_model = BertEmbeddingModel(\n",
    "        device=device,\n",
    "        pooling_strat=pooling_strategy,\n",
    "        scale=False\n",
    "    )\n",
    "    \n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5, step=0.01)\n",
    "#     lstm dropout only works with multiple lstm layers\n",
    "#     lstm_dropout = trial.suggest_float('lstm_dropout', 0.0, 0.3, step=0.05)\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [128, 256, 512])\n",
    "#     dropout = 0.4\n",
    "#     lstm_dropout = 0.0\n",
    "#     hidden_dim = 128\n",
    "    w_seq = trial.suggest_categorical('with_sequential_layer', [True, False])\n",
    "    model = BiLSTM(\n",
    "        dropout=dropout,\n",
    "        hidden_dim=hidden_dim,\n",
    "        embedding_dim=embedding_model.dim,\n",
    "        sent_level_feature_dim=0,\n",
    "        device=device,\n",
    "        w_seq=w_seq,\n",
    "    ).to(device)    \n",
    "\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    opt_weight_decay = trial.suggest_float('optimizer_weigth_decay', 1e-6, 0.1, log=True)\n",
    "#     lr = 0.001\n",
    "#     opt_weight_decay = 0\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=opt_weight_decay)\n",
    "\n",
    "    pos_weight = trial.suggest_categorical('pos_weight', [1.0, train_uw_ratio])\n",
    "#     pos_weight = train_uw_ratio\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]).to(device))\n",
    "\n",
    "    n_epochs = 16\n",
    "    threshold = 0.5\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=5,\n",
    "        path=None,\n",
    "        verbose=False,\n",
    "        trace_func=print_n_log.run('early_stopping', logf_path, 'DEBUG')\n",
    "    )\n",
    "    \n",
    "    # training\n",
    "    for epoch in range(n_epochs):\n",
    "        losses, val_losses = [], []\n",
    "\n",
    "        model.train()\n",
    "        for ids, sentences, labels, features in train_loader:\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            embeddings, lengths = embedding_model(sentences)\n",
    "            output = model(embeddings, lengths)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        y_pred, y_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for val_ids, val_sentences, val_labels, val_features in val_loader:\n",
    "                val_labels = val_labels.float().to(device)\n",
    "                \n",
    "                val_embeddings, val_lengths = embedding_model(val_sentences)\n",
    "                pred = model(val_embeddings, val_lengths)\n",
    "                val_loss = criterion(pred, val_labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                pred = torch.sigmoid(pred)\n",
    "                \n",
    "                pred = (pred > threshold).int()\n",
    "                y_pred.extend(pred.tolist())\n",
    "                y_true.extend(val_labels.tolist())\n",
    "        \n",
    "#         print('epoch: ', epoch)\n",
    "#         print('avg train loss: ', sum(losses) / len(losses))\n",
    "#         print('avg val loss: ', sum(val_losses) / len(val_losses))\n",
    "#         print(classification_report(y_true, y_pred, digits=6))\n",
    "        cr = classification_report(y_true, y_pred, digits=6, output_dict=True, zero_division=0)\n",
    "        \n",
    "        val_loss = np.average(val_losses)\n",
    "        early_stopping(val_loss, model, acomp_metrics={'recall_p': cr['1.0']['recall']})\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "#         trial.report(recall_p, epoch)\n",
    "\n",
    "#         # Handle pruning based on the intermediate value.\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.exceptions.TrialPruned()\n",
    "    recall_p = early_stopping.acomp_metrics['recall_p'] if early_stopping.acomp_metrics else 0.0\n",
    "    \"Done.\"\n",
    "    return recall_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-25 14:24:30,809]\u001b[0m A new study created in memory with name: bi-lstm_wAtt_sTPE_pNone_df0.2_wf0.2\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:26:57,904]\u001b[0m Trial 0 finished with value: 0.10784313725490197 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.46, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 1.793694160621985e-05, 'optimizer_weigth_decay': 0.06239219845566065, 'pos_weight': 1.0}. Best is trial 0 with value: 0.10784313725490197.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:28:07,922]\u001b[0m Trial 1 finished with value: 0.24 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.25, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.00039108196961779994, 'optimizer_weigth_decay': 3.324629083106019e-05, 'pos_weight': 1.0}. Best is trial 1 with value: 0.24.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:30:31,318]\u001b[0m Trial 2 finished with value: 0.39603960396039606 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.48, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 2.4193179321802653e-05, 'optimizer_weigth_decay': 0.003666987492522454, 'pos_weight': 1.0}. Best is trial 2 with value: 0.39603960396039606.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:32:17,173]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.15, 'hidden_dim': 512, 'with_sequential_layer': False, 'learning_rate': 0.07552859928211417, 'optimizer_weigth_decay': 0.004710769567624248, 'pos_weight': 1.0}. Best is trial 2 with value: 0.39603960396039606.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:33:37,941]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four_sum', 'dropout': 0.28, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.0032213180312841623, 'optimizer_weigth_decay': 0.09976822354743628, 'pos_weight': 1.0}. Best is trial 2 with value: 0.39603960396039606.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:34:44,490]\u001b[0m Trial 5 finished with value: 0.7254901960784313 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four_sum', 'dropout': 0.15, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 2.9028664584180982e-05, 'optimizer_weigth_decay': 0.00045978137877951647, 'pos_weight': 5.902366863905326}. Best is trial 5 with value: 0.7254901960784313.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:36:37,884]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.41000000000000003, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 1.13930449304587e-05, 'optimizer_weigth_decay': 0.07543084099081832, 'pos_weight': 5.902366863905326}. Best is trial 5 with value: 0.7254901960784313.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:37:32,630]\u001b[0m Trial 7 finished with value: 0.06 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.16, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.000519990158037128, 'optimizer_weigth_decay': 0.0009111522803563766, 'pos_weight': 1.0}. Best is trial 5 with value: 0.7254901960784313.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:38:47,008]\u001b[0m Trial 8 finished with value: 0.7843137254901961 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.09, 'hidden_dim': 512, 'with_sequential_layer': False, 'learning_rate': 0.0033056894014851174, 'optimizer_weigth_decay': 0.0004999823673463902, 'pos_weight': 5.902366863905326}. Best is trial 8 with value: 0.7843137254901961.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:39:50,254]\u001b[0m Trial 9 finished with value: 0.7843137254901961 and parameters: {'batch_size': 64, 'pooling_strategy': 'second_last', 'dropout': 0.36, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.020791085999740718, 'optimizer_weigth_decay': 0.0002724392631622774, 'pos_weight': 5.902366863905326}. Best is trial 8 with value: 0.7843137254901961.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:40:54,287]\u001b[0m Trial 10 finished with value: 0.7722772277227723 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.03, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.0046909931871849065, 'optimizer_weigth_decay': 1.1454956184443864e-06, 'pos_weight': 5.902366863905326}. Best is trial 8 with value: 0.7843137254901961.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:42:23,646]\u001b[0m Trial 11 finished with value: 0.7647058823529411 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.32, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.028034544389788356, 'optimizer_weigth_decay': 7.189454184428164e-05, 'pos_weight': 5.902366863905326}. Best is trial 8 with value: 0.7843137254901961.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:43:17,675]\u001b[0m Trial 12 finished with value: 0.8514851485148515 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.010452067178520229, 'optimizer_weigth_decay': 3.313838660810591e-05, 'pos_weight': 5.902366863905326}. Best is trial 12 with value: 0.8514851485148515.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:44:31,650]\u001b[0m Trial 13 finished with value: 0.696969696969697 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.02, 'hidden_dim': 512, 'with_sequential_layer': False, 'learning_rate': 0.0028136067168969855, 'optimizer_weigth_decay': 8.816030487518482e-06, 'pos_weight': 5.902366863905326}. Best is trial 12 with value: 0.8514851485148515.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:45:49,638]\u001b[0m Trial 14 finished with value: 0.6831683168316832 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.08, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.00012333352694205558, 'optimizer_weigth_decay': 7.904887390940993e-06, 'pos_weight': 5.902366863905326}. Best is trial 12 with value: 0.8514851485148515.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:48:14,737]\u001b[0m Trial 15 finished with value: 0.8235294117647058 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.1, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.010689032370195624, 'optimizer_weigth_decay': 8.246317644630291e-05, 'pos_weight': 5.902366863905326}. Best is trial 12 with value: 0.8514851485148515.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:49:25,376]\u001b[0m Trial 16 finished with value: 0.78 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four_sum', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.013697413312740714, 'optimizer_weigth_decay': 6.193256972904103e-05, 'pos_weight': 5.902366863905326}. Best is trial 12 with value: 0.8514851485148515.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:51:04,322]\u001b[0m Trial 17 finished with value: 0.49019607843137253 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.22, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.08346182596115011, 'optimizer_weigth_decay': 8.117775688458958e-06, 'pos_weight': 5.902366863905326}. Best is trial 12 with value: 0.8514851485148515.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:52:06,079]\u001b[0m Trial 18 finished with value: 0.8725490196078431 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.08, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.009829039084607008, 'optimizer_weigth_decay': 1.4510367400399084e-06, 'pos_weight': 5.902366863905326}. Best is trial 18 with value: 0.8725490196078431.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:52:59,889]\u001b[0m Trial 19 finished with value: 0.7425742574257426 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four_sum', 'dropout': 0.2, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0011198537033429885, 'optimizer_weigth_decay': 1.13208927034809e-06, 'pos_weight': 5.902366863905326}. Best is trial 18 with value: 0.8725490196078431.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:54:39,863]\u001b[0m Trial 20 finished with value: 0.8080808080808081 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.06, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.038876766662014485, 'optimizer_weigth_decay': 2.55081532153902e-06, 'pos_weight': 5.902366863905326}. Best is trial 18 with value: 0.8725490196078431.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:56:31,274]\u001b[0m Trial 21 finished with value: 0.78 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.12, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.008918567074320372, 'optimizer_weigth_decay': 2.1070535431899254e-05, 'pos_weight': 5.902366863905326}. Best is trial 18 with value: 0.8725490196078431.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:58:14,446]\u001b[0m Trial 22 finished with value: 0.8787878787878788 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.05, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.009739382987441973, 'optimizer_weigth_decay': 9.156768502693764e-05, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 14:59:08,023]\u001b[0m Trial 23 finished with value: 0.8712871287128713 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.05, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0016603042277144623, 'optimizer_weigth_decay': 0.00017585549384679282, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:00:10,818]\u001b[0m Trial 24 finished with value: 0.7128712871287128 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.06, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.00103170349493579, 'optimizer_weigth_decay': 0.0026339251551975003, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:01:21,145]\u001b[0m Trial 25 finished with value: 0.79 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.05, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0001370517560025726, 'optimizer_weigth_decay': 0.00017803254001184165, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:02:39,723]\u001b[0m Trial 26 finished with value: 0.693069306930693 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.12, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0018041117160404177, 'optimizer_weigth_decay': 0.013236445834677348, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:03:33,639]\u001b[0m Trial 27 finished with value: 0.7647058823529411 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.18, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.006536975376230815, 'optimizer_weigth_decay': 4.568297639746686e-06, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:04:28,036]\u001b[0m Trial 28 finished with value: 0.7575757575757576 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.11, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0002787306594229575, 'optimizer_weigth_decay': 0.0013180689169140975, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:05:24,220]\u001b[0m Trial 29 finished with value: 0.0 and parameters: {'batch_size': 16, 'pooling_strategy': 'last_four_sum', 'dropout': 0.05, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.04026590264394987, 'optimizer_weigth_decay': 0.00015196882203813775, 'pos_weight': 1.0}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:06:36,203]\u001b[0m Trial 30 finished with value: 0.8514851485148515 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0015789311053395834, 'optimizer_weigth_decay': 0.020624433049539207, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:07:57,100]\u001b[0m Trial 31 finished with value: 0.71 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0018543860349141755, 'optimizer_weigth_decay': 0.01976394621036234, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:09:08,885]\u001b[0m Trial 32 finished with value: 0.7373737373737373 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.04, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0005772954783666589, 'optimizer_weigth_decay': 0.0188064482302706, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:11:04,189]\u001b[0m Trial 33 finished with value: 0.7254901960784313 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.08, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.006084225782558756, 'optimizer_weigth_decay': 0.008155210536424973, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:12:35,007]\u001b[0m Trial 34 finished with value: 0.33 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.14, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.0014659708137205038, 'optimizer_weigth_decay': 0.0012881502838648412, 'pos_weight': 1.0}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:14:38,064]\u001b[0m Trial 35 finished with value: 0.3465346534653465 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0007178493973499014, 'optimizer_weigth_decay': 0.036629716606798285, 'pos_weight': 1.0}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:15:41,767]\u001b[0m Trial 36 finished with value: 0.7346938775510204 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.25, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.019265758043706022, 'optimizer_weigth_decay': 2.5499514111542232e-05, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:17:12,247]\u001b[0m Trial 37 finished with value: 0.7647058823529411 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.07, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.0027105716479400356, 'optimizer_weigth_decay': 1.5594632868957544e-05, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:19:31,007]\u001b[0m Trial 38 finished with value: 0.0 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four_sum', 'dropout': 0.48, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.00463852462138541, 'optimizer_weigth_decay': 0.00319896577463008, 'pos_weight': 1.0}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:21:24,556]\u001b[0m Trial 39 finished with value: 0.75 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.03, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.01247809044202294, 'optimizer_weigth_decay': 5.4666559381872055e-05, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:22:26,393]\u001b[0m Trial 40 finished with value: 0.7920792079207921 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.44, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.00028196126760969206, 'optimizer_weigth_decay': 0.0005775754786295129, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:24:01,511]\u001b[0m Trial 41 finished with value: 0.6274509803921569 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.007107990223874346, 'optimizer_weigth_decay': 0.0001386218091573676, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:25:45,116]\u001b[0m Trial 42 finished with value: 0.7254901960784313 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.03, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.047955698799982766, 'optimizer_weigth_decay': 0.00025402060349302366, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:26:54,996]\u001b[0m Trial 43 finished with value: 0.8415841584158416 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.019199733255337165, 'optimizer_weigth_decay': 3.0065278982940446e-06, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:27:57,027]\u001b[0m Trial 44 finished with value: 0.6764705882352942 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.09, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.004055399772471766, 'optimizer_weigth_decay': 0.0003517867822325347, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:29:19,625]\u001b[0m Trial 45 finished with value: 0.8235294117647058 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.05, 'hidden_dim': 512, 'with_sequential_layer': False, 'learning_rate': 0.002685892204798994, 'optimizer_weigth_decay': 4.99646046304183e-05, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:30:38,569]\u001b[0m Trial 46 finished with value: 0.13861386138613863 and parameters: {'batch_size': 64, 'pooling_strategy': 'second_last', 'dropout': 0.15, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.01615108804828439, 'optimizer_weigth_decay': 3.4619735227164376e-05, 'pos_weight': 1.0}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:32:06,156]\u001b[0m Trial 47 finished with value: 0.85 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.31, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.028278333398865173, 'optimizer_weigth_decay': 0.00010443764166189848, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:33:29,981]\u001b[0m Trial 48 finished with value: 0.81 and parameters: {'batch_size': 16, 'pooling_strategy': 'last_four', 'dropout': 0.13, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 3.406859994601663e-05, 'optimizer_weigth_decay': 0.0007886539325411238, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:35:28,912]\u001b[0m Trial 49 finished with value: 0.7549019607843137 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four_sum', 'dropout': 0.09, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.010293532880792253, 'optimizer_weigth_decay': 1.911810787472626e-06, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:36:30,408]\u001b[0m Trial 50 finished with value: 0.693069306930693 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.03, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.0007401221595373045, 'optimizer_weigth_decay': 3.926850030667104e-05, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:38:31,520]\u001b[0m Trial 51 finished with value: 0.8137254901960784 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.29, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.022759030463386072, 'optimizer_weigth_decay': 9.076931029433165e-05, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:39:42,071]\u001b[0m Trial 52 finished with value: 0.7029702970297029 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.32, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.06342065352400839, 'optimizer_weigth_decay': 1.194052275478262e-05, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:41:17,649]\u001b[0m Trial 53 finished with value: 0.803921568627451 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.38, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.030200689303996674, 'optimizer_weigth_decay': 0.00012014974508334106, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:42:53,569]\u001b[0m Trial 54 finished with value: 0.7623762376237624 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.3, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.009407517054186713, 'optimizer_weigth_decay': 0.00026630851335286525, 'pos_weight': 5.902366863905326}. Best is trial 22 with value: 0.8787878787878788.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:45:11,563]\u001b[0m Trial 55 finished with value: 0.8888888888888888 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.22, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.028856351451488176, 'optimizer_weigth_decay': 4.988195595031759e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:46:13,281]\u001b[0m Trial 56 finished with value: 0.84 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.17, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.0021070435424871865, 'optimizer_weigth_decay': 3.5461532769747883e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:47:18,209]\u001b[0m Trial 57 finished with value: 0.79 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.07, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.059976664399853157, 'optimizer_weigth_decay': 5.398289713190731e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:48:41,997]\u001b[0m Trial 58 finished with value: 0.7941176470588235 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.19, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.0036518081760250833, 'optimizer_weigth_decay': 1.4939653031262234e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:50:35,043]\u001b[0m Trial 59 finished with value: 0.0 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four_sum', 'dropout': 0.27, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.09119475890087839, 'optimizer_weigth_decay': 6.285921951973762e-06, 'pos_weight': 1.0}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:51:29,646]\u001b[0m Trial 60 finished with value: 0.7722772277227723 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.21, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.005830258359531063, 'optimizer_weigth_decay': 1.8779478389318157e-05, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:52:48,646]\u001b[0m Trial 61 finished with value: 0.7843137254901961 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.23, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.014391796447435243, 'optimizer_weigth_decay': 9.00088063354566e-05, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:53:50,470]\u001b[0m Trial 62 finished with value: 0.76 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.01, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.026572959243945215, 'optimizer_weigth_decay': 0.00018871618292240098, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:55:09,783]\u001b[0m Trial 63 finished with value: 0.8 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.34, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.03541356807111707, 'optimizer_weigth_decay': 1.0445234356560589e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:56:45,553]\u001b[0m Trial 64 finished with value: 0.8235294117647058 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.27, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.0013860983742986902, 'optimizer_weigth_decay': 1.1867286939299188e-05, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:57:46,534]\u001b[0m Trial 65 finished with value: 0.77 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.38, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.007779146585700016, 'optimizer_weigth_decay': 2.858338055365945e-05, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:58:41,740]\u001b[0m Trial 66 finished with value: 0.8367346938775511 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.11, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.052055875620059325, 'optimizer_weigth_decay': 0.00036788605225857236, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 15:59:46,565]\u001b[0m Trial 67 finished with value: 0.8367346938775511 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.06, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.012911958628475615, 'optimizer_weigth_decay': 2.4845371635400842e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:00:48,826]\u001b[0m Trial 68 finished with value: 0.6868686868686869 and parameters: {'batch_size': 64, 'pooling_strategy': 'second_last', 'dropout': 0.04, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0004191064057613735, 'optimizer_weigth_decay': 0.0017526850576414167, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:02:50,036]\u001b[0m Trial 69 finished with value: 0.76 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.018227084679724313, 'optimizer_weigth_decay': 6.460454457390899e-05, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:03:52,914]\u001b[0m Trial 70 finished with value: 0.0 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.0, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.004965490112032601, 'optimizer_weigth_decay': 0.05214277485120749, 'pos_weight': 1.0}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:04:54,772]\u001b[0m Trial 71 finished with value: 0.6464646464646465 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.025914216292206787, 'optimizer_weigth_decay': 2.7248863142833876e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:06:30,159]\u001b[0m Trial 72 finished with value: 0.7058823529411765 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.04, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.020948523914372345, 'optimizer_weigth_decay': 3.945308786966878e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:07:40,414]\u001b[0m Trial 73 finished with value: 0.87 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.010105267932888596, 'optimizer_weigth_decay': 1.9076857822647095e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:08:50,449]\u001b[0m Trial 74 finished with value: 0.7227722772277227 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.07, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.008774595936663063, 'optimizer_weigth_decay': 9.992924399584122e-05, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:10:17,253]\u001b[0m Trial 75 finished with value: 0.7272727272727273 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.037805781875804655, 'optimizer_weigth_decay': 0.00020609177844938036, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:11:12,013]\u001b[0m Trial 76 finished with value: 0.56 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four_sum', 'dropout': 0.05, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.011033538228774, 'optimizer_weigth_decay': 1.2514161394157121e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:12:20,691]\u001b[0m Trial 77 finished with value: 0.6237623762376238 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.1, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.0029320566287059082, 'optimizer_weigth_decay': 1.5074018010439305e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:13:39,136]\u001b[0m Trial 78 finished with value: 0.6 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.006016515667592613, 'optimizer_weigth_decay': 1.9238206184352277e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:14:33,386]\u001b[0m Trial 79 finished with value: 0.803921568627451 and parameters: {'batch_size': 64, 'pooling_strategy': 'second_last', 'dropout': 0.08, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0014792760151694279, 'optimizer_weigth_decay': 4.277593328921188e-05, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:16:49,774]\u001b[0m Trial 80 finished with value: 0.7575757575757576 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.33, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 6.136114297707611e-05, 'optimizer_weigth_decay': 0.00044219745417339385, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:17:59,877]\u001b[0m Trial 81 finished with value: 0.7623762376237624 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.016000124215970878, 'optimizer_weigth_decay': 7.934710070957767e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:19:42,502]\u001b[0m Trial 82 finished with value: 0.693069306930693 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.04, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.01904707793129309, 'optimizer_weigth_decay': 0.006200035198861812, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:21:17,369]\u001b[0m Trial 83 finished with value: 0.8333333333333334 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.03165905408634895, 'optimizer_weigth_decay': 2.9479073628457992e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:22:35,624]\u001b[0m Trial 84 finished with value: 0.801980198019802 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.013003292996120333, 'optimizer_weigth_decay': 4.7008626034885205e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:24:46,216]\u001b[0m Trial 85 finished with value: 0.72 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.03, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.007787999876153342, 'optimizer_weigth_decay': 1.7220486046401775e-06, 'pos_weight': 5.902366863905326}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:25:59,692]\u001b[0m Trial 86 finished with value: 0.29411764705882354 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.06, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.005012933471525653, 'optimizer_weigth_decay': 0.00012762078466336553, 'pos_weight': 1.0}. Best is trial 55 with value: 0.8888888888888888.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:27:02,240]\u001b[0m Trial 87 finished with value: 0.9215686274509803 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.23, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.002239946894224584, 'optimizer_weigth_decay': 1.0179657243851676e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:28:29,609]\u001b[0m Trial 88 finished with value: 0.6565656565656566 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.22, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.002265079494537101, 'optimizer_weigth_decay': 1.2225266116173789e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:29:41,665]\u001b[0m Trial 89 finished with value: 0.74 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four_sum', 'dropout': 0.25, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.00080430053631475, 'optimizer_weigth_decay': 2.0350013539937658e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:30:52,297]\u001b[0m Trial 90 finished with value: 0.7647058823529411 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.24, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.00114818416540795, 'optimizer_weigth_decay': 6.332721113701758e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:31:54,417]\u001b[0m Trial 91 finished with value: 0.6435643564356436 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.31, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.003469025317165774, 'optimizer_weigth_decay': 3.7997927697778354e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:32:48,655]\u001b[0m Trial 92 finished with value: 0.7474747474747475 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.2, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.01105693565169385, 'optimizer_weigth_decay': 2.231591992569336e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:35:04,737]\u001b[0m Trial 93 finished with value: 0.86 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.44, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.045822594916345924, 'optimizer_weigth_decay': 1.0511933619586105e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:36:09,815]\u001b[0m Trial 94 finished with value: 0.5959595959595959 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.46, 'hidden_dim': 512, 'with_sequential_layer': False, 'learning_rate': 0.06962426407867915, 'optimizer_weigth_decay': 2.3156768873184734e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:38:08,029]\u001b[0m Trial 95 finished with value: 0.8217821782178217 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.5, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.046444903312127694, 'optimizer_weigth_decay': 9.884933418045504e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:39:43,919]\u001b[0m Trial 96 finished with value: 0.8 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.44, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.0020869275809954754, 'optimizer_weigth_decay': 3.105865358516717e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:41:49,952]\u001b[0m Trial 97 finished with value: 0.6831683168316832 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.4, 'hidden_dim': 512, 'with_sequential_layer': False, 'learning_rate': 0.024233046169053644, 'optimizer_weigth_decay': 1.7124830298300472e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:43:39,730]\u001b[0m Trial 98 finished with value: 0.8137254901960784 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.35000000000000003, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.004167725586035867, 'optimizer_weigth_decay': 1.4247960345027968e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:44:45,348]\u001b[0m Trial 99 finished with value: 0.37 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.16, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.0009255475734129148, 'optimizer_weigth_decay': 6.703711792445535e-06, 'pos_weight': 1.0}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:45:48,372]\u001b[0m Trial 100 finished with value: 0.801980198019802 and parameters: {'batch_size': 64, 'pooling_strategy': 'second_last', 'dropout': 0.26, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.0015378440527268823, 'optimizer_weigth_decay': 7.330720071678707e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:47:14,934]\u001b[0m Trial 101 finished with value: 0.8383838383838383 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.04, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.031634893459828124, 'optimizer_weigth_decay': 3.0091247625410223e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:48:08,615]\u001b[0m Trial 102 finished with value: 0.7040816326530612 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.044341773738175445, 'optimizer_weigth_decay': 4.958555335846008e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:50:17,008]\u001b[0m Trial 103 finished with value: 0.696078431372549 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0994912928853752, 'optimizer_weigth_decay': 4.8544346396703024e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:51:35,718]\u001b[0m Trial 104 finished with value: 0.7 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.05, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.015847305617894696, 'optimizer_weigth_decay': 9.653957052711912e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:53:18,662]\u001b[0m Trial 105 finished with value: 0.69 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.43, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.05741252477344551, 'optimizer_weigth_decay': 1.3159516228546772e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:55:41,237]\u001b[0m Trial 106 finished with value: 0.7524752475247525 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.37, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.009180040392385413, 'optimizer_weigth_decay': 0.00022506760917645921, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:57:29,798]\u001b[0m Trial 107 finished with value: 0.0 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.03, 'hidden_dim': 512, 'with_sequential_layer': False, 'learning_rate': 0.02277757790827968, 'optimizer_weigth_decay': 0.09290323169576135, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:58:23,621]\u001b[0m Trial 108 finished with value: 0.7920792079207921 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.06, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.006851458325315166, 'optimizer_weigth_decay': 0.0001500595893312337, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 16:59:17,107]\u001b[0m Trial 109 finished with value: 0.79 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four_sum', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0005908385235323246, 'optimizer_weigth_decay': 0.00030685599048390586, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:01:37,750]\u001b[0m Trial 110 finished with value: 0.7959183673469388 and parameters: {'batch_size': 64, 'pooling_strategy': 'second_last', 'dropout': 0.28, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 1.317657974152549e-05, 'optimizer_weigth_decay': 6.118030662632824e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:02:39,000]\u001b[0m Trial 111 finished with value: 0.7272727272727273 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.17, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.0012755110337159343, 'optimizer_weigth_decay': 3.6670688883086243e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:03:31,929]\u001b[0m Trial 112 finished with value: 0.71 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.23, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.07732279227062971, 'optimizer_weigth_decay': 3.3177837135028148e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:04:25,154]\u001b[0m Trial 113 finished with value: 0.696078431372549 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.19, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.0019461029746354005, 'optimizer_weigth_decay': 2.1212497193306293e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:05:34,856]\u001b[0m Trial 114 finished with value: 0.72 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.08, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.0025625608832232586, 'optimizer_weigth_decay': 2.381338203617962e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:06:27,759]\u001b[0m Trial 115 finished with value: 0.8118811881188119 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.13, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.0017650778900346077, 'optimizer_weigth_decay': 5.376959862423901e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:07:53,679]\u001b[0m Trial 116 finished with value: 0.7843137254901961 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.18, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.019192819716340636, 'optimizer_weigth_decay': 0.00011379872881683231, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:09:30,490]\u001b[0m Trial 117 finished with value: 0.76 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.01204025796765386, 'optimizer_weigth_decay': 7.373665313851398e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:11:41,154]\u001b[0m Trial 118 finished with value: 0.0 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.23, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.038987545623234816, 'optimizer_weigth_decay': 0.000622459583531744, 'pos_weight': 1.0}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:12:53,256]\u001b[0m Trial 119 finished with value: 0.7272727272727273 and parameters: {'batch_size': 16, 'pooling_strategy': 'second_last', 'dropout': 0.21, 'hidden_dim': 128, 'with_sequential_layer': False, 'learning_rate': 0.02770662850134814, 'optimizer_weigth_decay': 1.703212521629128e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:14:02,959]\u001b[0m Trial 120 finished with value: 0.76 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.09, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.015075216388379472, 'optimizer_weigth_decay': 4.302561898976144e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:15:46,773]\u001b[0m Trial 121 finished with value: 0.8333333333333334 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.03, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.033848410338707086, 'optimizer_weigth_decay': 3.0477412896411644e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:16:40,232]\u001b[0m Trial 122 finished with value: 0.7843137254901961 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.05, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0023904067685550077, 'optimizer_weigth_decay': 2.804131566315829e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:17:50,464]\u001b[0m Trial 123 finished with value: 0.7647058823529411 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.04, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0306364305571743, 'optimizer_weigth_decay': 1.126623949433986e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:18:52,491]\u001b[0m Trial 124 finished with value: 0.7941176470588235 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.005403744927626884, 'optimizer_weigth_decay': 0.0001676148020049362, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:19:45,686]\u001b[0m Trial 125 finished with value: 0.6176470588235294 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.03, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.018085468321993797, 'optimizer_weigth_decay': 9.709413968899612e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:20:51,779]\u001b[0m Trial 126 finished with value: 0.7941176470588235 and parameters: {'batch_size': 64, 'pooling_strategy': 'second_last', 'dropout': 0.07, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.002944983656270281, 'optimizer_weigth_decay': 5.8502665286059126e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:22:52,555]\u001b[0m Trial 127 finished with value: 0.7171717171717171 and parameters: {'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.01, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.008159627294835055, 'optimizer_weigth_decay': 0.011777127565209277, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:23:55,650]\u001b[0m Trial 128 finished with value: 0.8484848484848485 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.025159397301530013, 'optimizer_weigth_decay': 0.02737983520681032, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:25:07,312]\u001b[0m Trial 129 finished with value: 0.8282828282828283 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.0009244599918586903, 'optimizer_weigth_decay': 0.028518337659778844, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:26:02,432]\u001b[0m Trial 130 finished with value: 0.48514851485148514 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.0, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.013668644565592452, 'optimizer_weigth_decay': 0.023251433884461575, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:27:22,233]\u001b[0m Trial 131 finished with value: 0.84 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.04, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.022932891151535295, 'optimizer_weigth_decay': 3.5122111478906487e-06, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:29:07,398]\u001b[0m Trial 132 finished with value: 0.8415841584158416 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.022813830086689486, 'optimizer_weigth_decay': 0.056535316534424514, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:31:17,706]\u001b[0m Trial 133 finished with value: 0.45544554455445546 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.022355241669922716, 'optimizer_weigth_decay': 0.07951479150711363, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:32:21,003]\u001b[0m Trial 134 finished with value: 0.8910891089108911 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.011114611605746977, 'optimizer_weigth_decay': 3.6502691618100075e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:34:40,310]\u001b[0m Trial 135 finished with value: 0.8181818181818182 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.02, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.010272758422620537, 'optimizer_weigth_decay': 0.054204258582228215, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:36:09,024]\u001b[0m Trial 136 finished with value: 0.7843137254901961 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.01, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.018077201177887196, 'optimizer_weigth_decay': 0.013338664911638504, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:37:37,653]\u001b[0m Trial 137 finished with value: 0.7722772277227723 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.0, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.05256573031657485, 'optimizer_weigth_decay': 0.04338349230474182, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:39:41,023]\u001b[0m Trial 138 finished with value: 0.0 and parameters: {'batch_size': 64, 'pooling_strategy': 'last_four', 'dropout': 0.03, 'hidden_dim': 512, 'with_sequential_layer': True, 'learning_rate': 0.010992742935364853, 'optimizer_weigth_decay': 9.993844212483677e-05, 'pos_weight': 1.0}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:40:43,756]\u001b[0m Trial 139 finished with value: 0.8712871287128713 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.41000000000000003, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.027409763647678668, 'optimizer_weigth_decay': 0.030682733507934882, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:42:39,510]\u001b[0m Trial 140 finished with value: 0.81 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.44, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.026904863239284694, 'optimizer_weigth_decay': 4.285962454660004e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:43:34,340]\u001b[0m Trial 141 finished with value: 0.5 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.46, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.015769793281061085, 'optimizer_weigth_decay': 0.03408363581496316, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:44:54,216]\u001b[0m Trial 142 finished with value: 0.7254901960784313 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.39, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.03881776230428951, 'optimizer_weigth_decay': 0.02446950231765687, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:47:05,264]\u001b[0m Trial 143 finished with value: 0.8686868686868687 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.43, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.006967581432327441, 'optimizer_weigth_decay': 0.034155844944325504, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:48:33,935]\u001b[0m Trial 144 finished with value: 0.45544554455445546 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.41000000000000003, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.008077097525240879, 'optimizer_weigth_decay': 0.04345194151426254, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:49:28,637]\u001b[0m Trial 145 finished with value: 0.8137254901960784 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.42, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.013190098492807433, 'optimizer_weigth_decay': 0.06770168799481015, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:50:40,111]\u001b[0m Trial 146 finished with value: 0.74 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.42, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.006429543896480618, 'optimizer_weigth_decay': 0.015937942655323993, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:51:45,948]\u001b[0m Trial 147 finished with value: 0.6534653465346535 and parameters: {'batch_size': 16, 'pooling_strategy': 'last_four', 'dropout': 0.47000000000000003, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.010765331045384772, 'optimizer_weigth_decay': 7.859190372427884e-05, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:53:47,823]\u001b[0m Trial 148 finished with value: 0.86 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.41000000000000003, 'hidden_dim': 128, 'with_sequential_layer': True, 'learning_rate': 0.004226424412348667, 'optimizer_weigth_decay': 0.035400571866033646, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m[I 2022-03-25 17:54:44,006]\u001b[0m Trial 149 finished with value: 0.86 and parameters: {'batch_size': 32, 'pooling_strategy': 'last_four', 'dropout': 0.39, 'hidden_dim': 256, 'with_sequential_layer': True, 'learning_rate': 0.004118121646043269, 'optimizer_weigth_decay': 0.024466004952937492, 'pos_weight': 5.902366863905326}. Best is trial 87 with value: 0.9215686274509803.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# needed for GridSampler\n",
    "search_space = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'pooling_strategy': ['last_four', 'last_four_sum', 'second_last'],\n",
    "#     'should_scale_emb': [False, True],\n",
    "    'dropout': [i/100 for i in range(0, 51, 5)],\n",
    "    'hidden_dim': [128, 256, 512],\n",
    "    'optimizer_weigth_decay': [i/10000 for i in range(11)],\n",
    "    'learning_rate': round_to_first_non_zero([i/100000 for i in range_inc(0, 100000, 1, 10)]),\n",
    "    'pos_weight': [1.0, train_uw_ratio]\n",
    "}\n",
    "# print(search_space)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=f'bi-lstm_wAtt_sTPE_pNone_df{dataset_frac}_wf{worthy_frac}',\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "#     sampler=optuna.samplers.GridSampler(search_space),\n",
    "#     pruner=optuna.pruners.MedianPruner(),\n",
    "    direction='maximize'\n",
    ")\n",
    "logf_path = p.join(LOG_DIR_PATH, f'{study.study_name}.log')\n",
    "study.optimize(objective, n_trials=150)\n",
    "\n",
    "study_path = os.path.join(optim_path, f'{study.study_name}.pkl')\n",
    "torch.save(study, study_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.23, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.002239946894224584, 'optimizer_weigth_decay': 1.0179657243851676e-05, 'pos_weight': 5.902366863905326}\n",
      "FrozenTrial(number=87, values=[0.9215686274509803], datetime_start=datetime.datetime(2022, 3, 25, 16, 25, 59, 693023), datetime_complete=datetime.datetime(2022, 3, 25, 16, 27, 2, 239580), params={'batch_size': 32, 'pooling_strategy': 'second_last', 'dropout': 0.23, 'hidden_dim': 256, 'with_sequential_layer': False, 'learning_rate': 0.002239946894224584, 'optimizer_weigth_decay': 1.0179657243851676e-05, 'pos_weight': 5.902366863905326}, distributions={'batch_size': CategoricalDistribution(choices=(16, 32, 64)), 'pooling_strategy': CategoricalDistribution(choices=('last_four', 'last_four_sum', 'second_last')), 'dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.01), 'hidden_dim': CategoricalDistribution(choices=(128, 256, 512)), 'with_sequential_layer': CategoricalDistribution(choices=(True, False)), 'learning_rate': LogUniformDistribution(high=0.1, low=1e-05), 'optimizer_weigth_decay': LogUniformDistribution(high=0.1, low=1e-06), 'pos_weight': CategoricalDistribution(choices=(1.0, 5.902366863905326))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=87, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "loaded_study = torch.load(study_path)\n",
    "\n",
    "print(loaded_study.best_trial.params)\n",
    "print(loaded_study.best_trial)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0566b9ebc7a58507829be3d77002d1a3a0910233c54c7888c127aa3b7af58774"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
